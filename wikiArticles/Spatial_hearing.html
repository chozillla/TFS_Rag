<div class="mw-content-ltr mw-parser-output" dir="ltr" lang="en">
 <div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">
  Biological sound detection process
 </div>
 <style data-mw-deduplicate="TemplateStyles:r1236090951">
  .mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}
 </style>
 <div class="hatnote navigation-not-searchable" role="note">
  This article is about the biological process of sound localization. For sound localization via mechanical or electrical means, see
  <a href="/wiki/Acoustic_location" title="Acoustic location">
   acoustic location
  </a>
  and
  <a href="/wiki/3D_sound_localization" title="3D sound localization">
   3D sound localization
  </a>
  .
 </div>
 <style data-mw-deduplicate="TemplateStyles:r1236091366">
  .mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}
 </style>
 <table class="box-Lead_too_short plainlinks metadata ambox ambox-content ambox-lead_too_short" role="presentation">
  <tbody>
   <tr>
    <td class="mbox-image">
     <div class="mbox-image-div">
      <span typeof="mw:File">
       <a class="mw-file-description" href="/wiki/File:Wiki_letter_w.svg">
        <img class="mw-file-element" data-file-height="44" data-file-width="44" decoding="async" height="40" src="//upload.wikimedia.org/wikipedia/en/thumb/6/6c/Wiki_letter_w.svg/40px-Wiki_letter_w.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/6/6c/Wiki_letter_w.svg/60px-Wiki_letter_w.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/6/6c/Wiki_letter_w.svg/80px-Wiki_letter_w.svg.png 2x" width="40"/>
       </a>
      </span>
     </div>
    </td>
    <td class="mbox-text">
     <div class="mbox-text-span">
      This article's
      <a href="/wiki/Wikipedia:Manual_of_Style/Lead_section#Length" title="Wikipedia:Manual of Style/Lead section">
       lead section
      </a>
      <b>
       may be too short to adequately
       <a href="/wiki/Wikipedia:Summary_style" title="Wikipedia:Summary style">
        summarize
       </a>
       the key points
      </b>
      .
      <span class="hide-when-compact">
       Please consider expanding the lead to
       <a href="/wiki/Wikipedia:Manual_of_Style/Lead_section#Provide_an_accessible_overview" title="Wikipedia:Manual of Style/Lead section">
        provide an accessible overview
       </a>
       of all important aspects of the article.
      </span>
      <span class="date-container">
       <i>
        (
        <span class="date">
         April 2023
        </span>
        )
       </i>
      </span>
     </div>
    </td>
   </tr>
  </tbody>
 </table>
 <p>
  <b>
   Sound localization
  </b>
  is a listener's ability to identify the location or origin of a detected
  <a href="/wiki/Sound" title="Sound">
   sound
  </a>
  in direction and distance.
 </p>
 <p>
  The sound localization mechanisms of the mammalian
  <a href="/wiki/Auditory_system" title="Auditory system">
   auditory system
  </a>
  have been extensively studied. The auditory system uses several cues for sound source localization, including time difference and level difference (or intensity difference) between the ears, and spectral information.  Other animals, such as birds and reptiles, also use them but they may use them differently, and some also have localization cues which are absent in the human auditory system, such as the effects of ear movements.  Animals with the ability to localize sound have a clear evolutionary advantage.
 </p>
 <meta property="mw:PageProp/toc"/>
 <div class="mw-heading mw-heading2">
  <h2 id="How_sound_reaches_the_brain">
   How sound reaches the brain
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=1" title="Edit section: How sound reaches the brain">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Sound is the perceptual result of mechanical vibrations traveling through a medium such as air or water. Through the mechanisms of compression and rarefaction, sound waves travel through the air, bounce off the
  <a class="mw-redirect" href="/wiki/Pinna_(anatomy)" title="Pinna (anatomy)">
   pinna
  </a>
  and concha of the exterior ear, and enter the ear canal.  In mammals, the sound waves vibrate the tympanic membrane (
  <a class="mw-redirect" href="/wiki/Ear_drum" title="Ear drum">
   ear drum
  </a>
  ), causing the three bones of the
  <a href="/wiki/Middle_ear" title="Middle ear">
   middle ear
  </a>
  to vibrate, which then sends the energy through the
  <a href="/wiki/Oval_window" title="Oval window">
   oval window
  </a>
  and into the
  <a href="/wiki/Cochlea" title="Cochlea">
   cochlea
  </a>
  where it is changed into a chemical signal by
  <a class="mw-redirect" href="/wiki/Hair_cells" title="Hair cells">
   hair cells
  </a>
  in the
  <a href="/wiki/Organ_of_Corti" title="Organ of Corti">
   organ of Corti
  </a>
  , which
  <a href="/wiki/Synapse" title="Synapse">
   synapse
  </a>
  onto
  <a href="/wiki/Spiral_ganglion" title="Spiral ganglion">
   spiral ganglion
  </a>
  fibers that travel through the
  <a href="/wiki/Cochlear_nerve" title="Cochlear nerve">
   cochlear nerve
  </a>
  into the brain.
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Neural_interactions">
   Neural interactions
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=2" title="Edit section: Neural interactions">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  In
  <a href="/wiki/Vertebrate" title="Vertebrate">
   vertebrates
  </a>
  , interaural time differences are known to be calculated in the
  <a class="mw-redirect" href="/wiki/Superior_olivary_nucleus" title="Superior olivary nucleus">
   superior olivary nucleus
  </a>
  of the
  <a href="/wiki/Brainstem" title="Brainstem">
   brainstem
  </a>
  . According to
  <a href="/wiki/Lloyd_A._Jeffress" title="Lloyd A. Jeffress">
   Jeffress
  </a>
  ,
  <sup class="reference" id="cite_ref-1">
   <a href="#cite_note-1">
    [1]
   </a>
  </sup>
  this calculation relies on
  <a href="/wiki/Analog_delay_line" title="Analog delay line">
   delay lines
  </a>
  :
  <a href="/wiki/Neuron" title="Neuron">
   neurons
  </a>
  in the superior olive which accept innervation from each ear with different connecting
  <a href="/wiki/Axon" title="Axon">
   axon
  </a>
  lengths. Some cells are more directly connected to one ear than the other, thus they are specific for a particular interaural time difference. This theory is equivalent to the mathematical procedure of
  <a href="/wiki/Cross-correlation" title="Cross-correlation">
   cross-correlation
  </a>
  . However, because Jeffress's theory is unable to account for the
  <a href="/wiki/Precedence_effect" title="Precedence effect">
   precedence effect
  </a>
  , in which only the first of multiple identical sounds is used to determine the sounds' location (thus avoiding confusion caused by echoes), it cannot be entirely used to explain the response. Furthermore, a number of recent physiological observations made in the midbrain and brainstem of small mammals have shed considerable doubt on the validity of Jeffress's original ideas.
  <sup class="reference" id="cite_ref-2">
   <a href="#cite_note-2">
    [2]
   </a>
  </sup>
 </p>
 <p>
  Neurons sensitive to interaural level differences (ILDs) are excited by stimulation of one ear and inhibited by stimulation of the other ear, such that the response magnitude of the cell depends on the relative strengths of the two inputs, which in turn, depends on the sound intensities at the ears.
 </p>
 <p>
  In the auditory midbrain nucleus, the
  <a href="/wiki/Inferior_colliculus" title="Inferior colliculus">
   inferior colliculus
  </a>
  (IC), many ILD sensitive neurons have response functions that decline steeply from maximum to zero spikes as a function of ILD. However, there are also many neurons with much more shallow response functions that do not decline to zero spikes.
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Human_auditory_system">
   Human auditory system
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=3" title="Edit section: Human auditory system">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Sound localization is the process of determining the location of a
  <a href="/wiki/Sound" title="Sound">
   sound
  </a>
  source. The brain utilizes subtle differences in intensity, spectral, and timing cues to localize sound sources.
  <sup class="reference" id="cite_ref-3">
   <a href="#cite_note-3">
    [3]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-Thompson_4-0">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
 </p>
 <p>
  Localization can be described in terms of three-dimensional position: the azimuth or horizontal angle, the elevation or vertical angle, and the distance (for static sounds) or velocity (for moving sounds).
  <sup class="reference" id="cite_ref-Roads_5-0">
   <a href="#cite_note-Roads-5">
    [5]
   </a>
  </sup>
 </p>
 <p>
  The azimuth of a sound is signaled by the
  <a href="/wiki/Interaural_time_difference" title="Interaural time difference">
   difference in arrival times between the ears
  </a>
  , by the relative amplitude of high-frequency sounds (the shadow effect), and by the asymmetrical spectral reflections from various parts of our bodies, including torso, shoulders, and
  <a class="mw-redirect" href="/wiki/Pinna_(anatomy)" title="Pinna (anatomy)">
   pinnae
  </a>
  .
  <sup class="reference" id="cite_ref-Roads_5-1">
   <a href="#cite_note-Roads-5">
    [5]
   </a>
  </sup>
 </p>
 <p>
  The distance cues are the loss of amplitude, the loss of high frequencies, and the ratio of the direct signal to the reverberated signal.
  <sup class="reference" id="cite_ref-Roads_5-2">
   <a href="#cite_note-Roads-5">
    [5]
   </a>
  </sup>
 </p>
 <p>
  Depending on where the source is located, our head acts as a barrier to change the
  <a href="/wiki/Timbre" title="Timbre">
   timbre
  </a>
  , intensity, and
  <a class="mw-redirect" href="/wiki/Continuous_spectrum" title="Continuous spectrum">
   spectral
  </a>
  qualities of the sound, helping the brain orient where the sound emanated from.
  <sup class="reference" id="cite_ref-Thompson_4-1">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
  These minute differences between the two ears are known as interaural cues.
  <sup class="reference" id="cite_ref-Thompson_4-2">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
 </p>
 <p>
  Lower frequencies, with longer wavelengths, diffract the sound around the head forcing the brain to focus only on the phasing cues from the source.
  <sup class="reference" id="cite_ref-Thompson_4-3">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
 </p>
 <p>
  Helmut Haas discovered that we can discern the sound source despite additional reflections at 10 decibels louder than the original wave front, using the earliest arriving wave front.
  <sup class="reference" id="cite_ref-Thompson_4-4">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
  This principle is known as the
  <a class="mw-redirect" href="/wiki/Haas_effect" title="Haas effect">
   Haas effect
  </a>
  , a specific version of the
  <a href="/wiki/Precedence_effect" title="Precedence effect">
   precedence effect
  </a>
  .
  <sup class="reference" id="cite_ref-Thompson_4-5">
   <a href="#cite_note-Thompson-4">
    [4]
   </a>
  </sup>
  Haas measured down to even a 1 millisecond difference in timing between the original sound and reflected sound increased the spaciousness, allowing the brain to discern the true location of the original sound. The nervous system combines all early reflections into a single perceptual whole allowing the brain to process multiple different sounds at once.
  <sup class="reference" id="cite_ref-Benade_6-0">
   <a href="#cite_note-Benade-6">
    [6]
   </a>
  </sup>
  The nervous system will combine reflections that are within about 35 milliseconds of each other and that have a similar intensity.
  <sup class="reference" id="cite_ref-Benade_6-1">
   <a href="#cite_note-Benade-6">
    [6]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Duplex_theory">
   Duplex theory
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=4" title="Edit section: Duplex theory">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  To determine the lateral input direction (left, front, right), the
  <a href="/wiki/Auditory_system" title="Auditory system">
   auditory system
  </a>
  analyzes the following
  <a href="/wiki/Ear" title="Ear">
   ear
  </a>
  signal information:
 </p>
 <p>
  In 1907, Lord Rayleigh utilized tuning forks to generate monophonic excitation and studied the lateral sound localization theory on a human head model without auricle. He first presented the interaural clue difference based sound localization theory, which is known as Duplex Theory.
  <sup class="reference" id="cite_ref-7">
   <a href="#cite_note-7">
    [7]
   </a>
  </sup>
  Human ears are on different sides of the head, and thus have different coordinates in space. As shown in the duplex theory figure, since the distances between the acoustic source and ears are different, there are time difference and intensity difference between the sound signals of two ears. We call those kinds of differences as Interaural Time Difference (ITD) and Interaural Intensity Difference (IID) respectively.
 </p>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:Sound_localization_in_a_living_room.png">
   <img class="mw-file-element" data-file-height="522" data-file-width="423" decoding="async" height="271" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Sound_localization_in_a_living_room.png/220px-Sound_localization_in_a_living_room.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/56/Sound_localization_in_a_living_room.png/330px-Sound_localization_in_a_living_room.png 1.5x, //upload.wikimedia.org/wikipedia/commons/5/56/Sound_localization_in_a_living_room.png 2x" width="220"/>
  </a>
  <figcaption>
   Duplex theory
  </figcaption>
 </figure>
 <style data-mw-deduplicate="TemplateStyles:r1096954695/mw-parser-output/.tmulti">
  .mw-parser-output .tmulti .multiimageinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}
 </style>
 <div class="thumb tmulti tright">
  <div class="thumbinner multiimageinner" style="width:259px;max-width:259px">
   <div class="trow">
    <div class="tsingle" style="width:257px;max-width:257px">
     <div class="thumbimage">
      <span typeof="mw:File">
       <a class="mw-file-description" href="/wiki/File:Interaural_Diferencia_de_tiempo_(ITD)_entre_izquierdo_(inferior)_y_correcto_(superior)_orejas.jpg">
        <img alt="" class="mw-file-element" data-file-height="442" data-file-width="660" decoding="async" height="171" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg/255px-Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg/383px-Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg/510px-Interaural_Diferencia_de_tiempo_%28ITD%29_entre_izquierdo_%28inferior%29_y_correcto_%28superior%29_orejas.jpg 2x" width="255"/>
       </a>
      </span>
     </div>
     <div class="thumbcaption">
      <a href="/wiki/Interaural_time_difference" title="Interaural time difference">
       Interaural time difference
      </a>
      (ITD) between left ear (top) and right ear (bottom).
      <div class="paragraphbreak" style="margin-top:0.5em">
      </div>
      [
      <i>
       sound source
      </i>
      : 100 ms
      <a href="/wiki/White_noise" title="White noise">
       white noise
      </a>
      from right]
     </div>
    </div>
   </div>
   <div class="trow">
    <div class="tsingle" style="width:257px;max-width:257px">
     <div class="thumbimage">
      <span typeof="mw:File">
       <a class="mw-file-description" href="/wiki/File:ExempleILD.jpg">
        <img alt="" class="mw-file-element" data-file-height="242" data-file-width="670" decoding="async" height="92" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/ExempleILD.jpg/255px-ExempleILD.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/ExempleILD.jpg/383px-ExempleILD.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c3/ExempleILD.jpg/510px-ExempleILD.jpg 2x" width="255"/>
       </a>
      </span>
     </div>
     <div class="thumbcaption">
      <a class="mw-redirect" href="/wiki/Interaural_level_difference" title="Interaural level difference">
       Interaural level difference
      </a>
      (ILD) between left ear (left) and  right ear (right).
      <div class="paragraphbreak" style="margin-top:0.5em">
      </div>
      [
      <i>
       sound source
      </i>
      : a sweep from right]
     </div>
    </div>
   </div>
  </div>
 </div>
 <p>
  From the duplex theory figure we can see that for source B1 or source B2, there will be a propagation delay between two ears, which will generate the ITD. Simultaneously, human head and ears may have a shadowing effect on high-frequency signals, which will generate IID.
 </p>
 <ul>
  <li>
   <a href="/wiki/Interaural_time_difference" title="Interaural time difference">
    Interaural time difference
   </a>
   (ITD) – Sound from the right side reaches the right ear earlier than the left ear. The auditory system evaluates interaural time differences from: (a)
   <a class="mw-redirect" href="/wiki/Phase_delay" title="Phase delay">
    Phase delays
   </a>
   at low frequencies and (b)
   <a href="/wiki/Group_delay_and_phase_delay" title="Group delay and phase delay">
    group delays
   </a>
   at high frequencies.
  </li>
  <li>
   Theory and experiments show that ITD relates to the signal frequency
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          f
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle f}
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle f}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/>
   </span>
   . Suppose the angular position of the acoustic source is
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          θ
          <!-- θ -->
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle \theta }
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle \theta }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/>
   </span>
   , the head radius is
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle r}" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          r
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle r}
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle r}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0d1ecb613aa2984f0576f70f86650b7c2a132538" style="vertical-align: -0.338ex; width:1.049ex; height:1.676ex;"/>
   </span>
   and the acoustic velocity is
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle c}" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          c
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle c}
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle c}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;"/>
   </span>
   , the function of ITD is given by:
   <sup class="reference" id="cite_ref-:0_8-0">
    <a href="#cite_note-:0-8">
     [8]
    </a>
   </sup>
   <sup class="noprint Inline-Template" style="white-space:nowrap;">
    [
    <i>
     <a href="/wiki/Template:Harvard_citation_documentation#Wikilink_to_citation_does_not_work" title="Template:Harvard citation documentation">
      <span title="Template:Harvard citation documentation#Wikilink to citation does not work (July 2023)">
       citation not found
      </span>
     </a>
    </i>
    ]
   </sup>
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle ITD={\begin{cases}3\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f\leq {\text{4000Hz }}\\2\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f&gt;{\text{ 4000Hz}}\end{cases}}}" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          I
         </mi>
         <mi>
          T
         </mi>
         <mi>
          D
         </mi>
         <mo>
          =
         </mo>
         <mrow class="MJX-TeXAtom-ORD">
          <mrow>
           <mo>
            {
           </mo>
           <mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em">
            <mtr>
             <mtd>
              <mn>
               3
              </mn>
              <mo>
               ×
               <!-- × -->
              </mo>
              <mrow class="MJX-TeXAtom-ORD">
               <mfrac>
                <mi>
                 r
                </mi>
                <mi>
                 c
                </mi>
               </mfrac>
              </mrow>
              <mo>
               ×
               <!-- × -->
              </mo>
              <mi>
               sin
              </mi>
              <mo>
               ⁡
               <!-- ⁡ -->
              </mo>
              <mi>
               θ
               <!-- θ -->
              </mi>
              <mo>
               ,
              </mo>
             </mtd>
             <mtd>
              <mrow class="MJX-TeXAtom-ORD">
               <mtext>
                if
               </mtext>
              </mrow>
              <mi>
               f
              </mi>
              <mo>
               ≤
               <!-- ≤ -->
              </mo>
              <mrow class="MJX-TeXAtom-ORD">
               <mtext>
                4000Hz
               </mtext>
              </mrow>
             </mtd>
            </mtr>
            <mtr>
             <mtd>
              <mn>
               2
              </mn>
              <mo>
               ×
               <!-- × -->
              </mo>
              <mrow class="MJX-TeXAtom-ORD">
               <mfrac>
                <mi>
                 r
                </mi>
                <mi>
                 c
                </mi>
               </mfrac>
              </mrow>
              <mo>
               ×
               <!-- × -->
              </mo>
              <mi>
               sin
              </mi>
              <mo>
               ⁡
               <!-- ⁡ -->
              </mo>
              <mi>
               θ
               <!-- θ -->
              </mi>
              <mo>
               ,
              </mo>
             </mtd>
             <mtd>
              <mrow class="MJX-TeXAtom-ORD">
               <mtext>
                if
               </mtext>
              </mrow>
              <mi>
               f
              </mi>
              <mo>
               &gt;
              </mo>
              <mrow class="MJX-TeXAtom-ORD">
               <mtext>
                4000Hz
               </mtext>
              </mrow>
             </mtd>
            </mtr>
           </mtable>
           <mo fence="true" stretchy="true" symmetric="true">
           </mo>
          </mrow>
         </mrow>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle ITD={\begin{cases}3\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f\leq {\text{4000Hz }}\\2\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f&gt;{\text{ 4000Hz}}\end{cases}}}
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle ITD={\begin{cases}3\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f\leq {\text{4000Hz }}\\2\times {\frac {r}{c}}\times \sin \theta ,&amp;{\text{if }}f&gt;{\text{ 4000Hz}}\end{cases}}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82ca2b13b4eabdac6b44e46f6eccd9672d835731" style="vertical-align: -2.505ex; width:40.371ex; height:6.176ex;"/>
   </span>
   . In above closed form, we assumed that the 0 degree is in the right ahead of the head and counter-clockwise is positive.
  </li>
  <li>
   Interaural intensity difference (IID) or interaural level difference (ILD) – Sound from the right side has a higher level at the right ear than at the left ear, because the
   <a href="/wiki/Head_shadow" title="Head shadow">
    head shadows
   </a>
   the left ear. These level differences are highly frequency dependent and they increase with increasing frequency.  Massive theoretical researches demonstrate that IID relates to the signal frequency
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          f
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle f}
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle f}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/>
   </span>
   and the angular position of the acoustic source
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          θ
          <!-- θ -->
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle \theta }
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle \theta }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/>
   </span>
   . The function of IID is given by:
   <sup class="reference" id="cite_ref-:0_8-1">
    <a href="#cite_note-:0-8">
     [8]
    </a>
   </sup>
   <sup class="noprint Inline-Template" style="white-space:nowrap;">
    [
    <i>
     <a href="/wiki/Template:Harvard_citation_documentation#Wikilink_to_citation_does_not_work" title="Template:Harvard citation documentation">
      <span title="Template:Harvard citation documentation#Wikilink to citation does not work (July 2023)">
       citation not found
      </span>
     </a>
    </i>
    ]
   </sup>
   <span class="mwe-math-element">
    <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
     <math alttext="{\displaystyle IID=1.0+(f/1000)^{0.8}\times \sin \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
      <semantics>
       <mrow class="MJX-TeXAtom-ORD">
        <mstyle displaystyle="true" scriptlevel="0">
         <mi>
          I
         </mi>
         <mi>
          I
         </mi>
         <mi>
          D
         </mi>
         <mo>
          =
         </mo>
         <mn>
          1.0
         </mn>
         <mo>
          +
         </mo>
         <mo stretchy="false">
          (
         </mo>
         <mi>
          f
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mo>
           /
          </mo>
         </mrow>
         <mn>
          1000
         </mn>
         <msup>
          <mo stretchy="false">
           )
          </mo>
          <mrow class="MJX-TeXAtom-ORD">
           <mn>
            0.8
           </mn>
          </mrow>
         </msup>
         <mo>
          ×
          <!-- × -->
         </mo>
         <mi>
          sin
         </mi>
         <mo>
          ⁡
          <!-- ⁡ -->
         </mo>
         <mi>
          θ
          <!-- θ -->
         </mi>
        </mstyle>
       </mrow>
       <annotation encoding="application/x-tex">
        {\displaystyle IID=1.0+(f/1000)^{0.8}\times \sin \theta }
       </annotation>
      </semantics>
     </math>
    </span>
    <img alt="{\displaystyle IID=1.0+(f/1000)^{0.8}\times \sin \theta }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e736217447c2be09c79aa188f04e549ffbb009f" style="vertical-align: -0.838ex; width:31.586ex; height:3.176ex;"/>
   </span>
  </li>
  <li>
   For frequencies below 1000 Hz, mainly ITDs are evaluated (
   <a class="mw-redirect" href="/wiki/Phase_delay" title="Phase delay">
    phase delays
   </a>
   ), for frequencies above 1500 Hz mainly IIDs are evaluated. Between 1000 Hz and 1500 Hz there is a transition zone, where both mechanisms play a role.
  </li>
  <li>
   Localization accuracy is 1 degree for sources in front of the listener and 15 degrees for sources to the sides. Humans can discern interaural time differences of 10 microseconds or less.
   <sup class="reference" id="cite_ref-9">
    <a href="#cite_note-9">
     [9]
    </a>
   </sup>
   <sup class="reference" id="cite_ref-10">
    <a href="#cite_note-10">
     [10]
    </a>
   </sup>
  </li>
 </ul>
 <p>
  For frequencies below 800 Hz, the dimensions of the head (ear distance 21.5 cm, corresponding to an interaural time delay of 626 μs) are smaller than the half
  <a href="/wiki/Wavelength" title="Wavelength">
   wavelength
  </a>
  of the sound waves. So the auditory system can determine phase delays between both ears without confusion. Interaural level differences are very low in this frequency range, especially below about 200 Hz, so a precise evaluation of the input direction is nearly impossible on the basis of level differences alone. As the frequency drops below 80 Hz it becomes difficult or impossible to use either time difference or level difference to determine a sound's lateral source, because the phase difference between the ears becomes too small for a directional evaluation.
  <sup class="reference" id="cite_ref-11">
   <a href="#cite_note-11">
    [11]
   </a>
  </sup>
 </p>
 <p>
  For frequencies above 1600 Hz the dimensions of the head are greater than the length of the sound waves. An unambiguous determination of the input direction based on interaural phase alone is not possible at these frequencies. However, the interaural level differences become larger, and these level differences are evaluated by the auditory system. Also, delays between the ears can still be detected via some combination of phase differences and
  <a href="/wiki/Group_delay_and_phase_delay" title="Group delay and phase delay">
   group delays
  </a>
  , which are more pronounced at higher frequencies; that is, if there is a sound onset, the delay of this onset between the ears can be used to determine the input direction of the corresponding sound source. This mechanism becomes especially important in reverberant environments. After a sound onset there is a short time frame where the direct sound reaches the ears, but not yet the reflected sound. The auditory system uses this short time frame for evaluating the sound source direction, and keeps this detected direction as long as reflections and reverberation prevent an unambiguous direction estimation.
  <sup class="reference" id="cite_ref-WNR_12-0">
   <a href="#cite_note-WNR-12">
    [12]
   </a>
  </sup>
  The mechanisms described above cannot be used to differentiate between a sound source ahead of the hearer or behind the hearer; therefore additional cues have to be evaluated.
  <sup class="reference" id="cite_ref-HW1940_13-0">
   <a href="#cite_note-HW1940-13">
    [13]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Pinna_filtering_effect">
   Pinna filtering effect
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=5" title="Edit section: Pinna filtering effect">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:HRTF.svg">
   <img class="mw-file-element" data-file-height="1052" data-file-width="744" decoding="async" height="311" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/50/HRTF.svg/220px-HRTF.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/50/HRTF.svg/330px-HRTF.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/50/HRTF.svg/440px-HRTF.svg.png 2x" width="220"/>
  </a>
  <figcaption>
   HRTF
  </figcaption>
 </figure>
 <p>
  Duplex theory shows that ITD and IID play significant roles in sound localization, but they can only deal with lateral localization problems. For example, if two acoustic sources are placed symmetrically at the front and back of the right side of the human head, they will generate equal ITDs and IIDs, in what is called the cone model effect. However, human ears can still distinguish between these sources. Besides that, in natural sense of hearing, one ear alone, without any ITD or IID, can distinguish between them with high accuracy.  Due to the disadvantages of duplex theory, researchers proposed the pinna filtering effect theory.
  <sup class="reference" id="cite_ref-nw61_14-0">
   <a href="#cite_note-nw61-14">
    [14]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-15">
   <a href="#cite_note-15">
    [15]
   </a>
  </sup>
  The shape of the human pinna is concave with complex folds and asymmetrical both horizontally and vertically. Reflected and direct waves generate a frequency spectrum on the eardrum, relating to the acoustic sources. Then auditory nerves localize the sources using this frequency spectrum.
  <sup class="reference" id="cite_ref-16">
   <a href="#cite_note-16">
    [16]
   </a>
  </sup>
 </p>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:Hrir_sintesi_binaurale.png">
   <img class="mw-file-element" data-file-height="599" data-file-width="432" decoding="async" height="305" src="//upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Hrir_sintesi_binaurale.png/220px-Hrir_sintesi_binaurale.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Hrir_sintesi_binaurale.png/330px-Hrir_sintesi_binaurale.png 1.5x, //upload.wikimedia.org/wikipedia/commons/0/0f/Hrir_sintesi_binaurale.png 2x" width="220"/>
  </a>
  <figcaption>
   HRIR
  </figcaption>
 </figure>
 <p>
  These spectrum clues generated by the pinna filtering effect can be presented as a
  <a href="/wiki/Head-related_transfer_function" title="Head-related transfer function">
   head-related transfer function
  </a>
  (HRTF). The corresponding time domain expressions are called the Head-Related Impulse Response (HRIR). The HRTF is also described as the transfer function from the free field to a specific point in the ear canal. We usually recognize HRTFs as LTI systems:
  <sup class="reference" id="cite_ref-:0_8-2">
   <a href="#cite_note-:0-8">
    [8]
   </a>
  </sup>
 </p>
 <p>
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle H_{L}=H_{L}(r,\theta ,\varphi ,\omega ,\alpha )=P_{L}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega )}" display="block" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           L
          </mi>
         </mrow>
        </msub>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           L
          </mi>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         θ
         <!-- θ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         φ
         <!-- φ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         α
         <!-- α -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           L
          </mi>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         θ
         <!-- θ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         φ
         <!-- φ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         α
         <!-- α -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mrow class="MJX-TeXAtom-ORD">
         <mo>
          /
         </mo>
        </mrow>
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mn>
           0
          </mn>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle H_{L}=H_{L}(r,\theta ,\varphi ,\omega ,\alpha )=P_{L}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega )}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle H_{L}=H_{L}(r,\theta ,\varphi ,\omega ,\alpha )=P_{L}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega )}" aria-hidden="true" class="mwe-math-fallback-image-display mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b297c96ca0ba6610a588ec33a684819fe5f4fbaa" style="vertical-align: -0.838ex; width:49.728ex; height:2.843ex;"/>
  </span>
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle H_{R}=H_{R}(r,\theta ,\varphi ,\omega ,\alpha )=P_{R}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega ),}" display="block" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           R
          </mi>
         </mrow>
        </msub>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           R
          </mi>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         θ
         <!-- θ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         φ
         <!-- φ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         α
         <!-- α -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         =
        </mo>
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           R
          </mi>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         θ
         <!-- θ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         φ
         <!-- φ -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         α
         <!-- α -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mrow class="MJX-TeXAtom-ORD">
         <mo>
          /
         </mo>
        </mrow>
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mn>
           0
          </mn>
         </mrow>
        </msub>
        <mo stretchy="false">
         (
        </mo>
        <mi>
         r
        </mi>
        <mo>
         ,
        </mo>
        <mi>
         ω
         <!-- ω -->
        </mi>
        <mo stretchy="false">
         )
        </mo>
        <mo>
         ,
        </mo>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle H_{R}=H_{R}(r,\theta ,\varphi ,\omega ,\alpha )=P_{R}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega ),}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle H_{R}=H_{R}(r,\theta ,\varphi ,\omega ,\alpha )=P_{R}(r,\theta ,\varphi ,\omega ,\alpha )/P_{0}(r,\omega ),}" aria-hidden="true" class="mwe-math-fallback-image-display mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cf46f3fbd76f4932b668454dfa09b51c7ca04acf" style="vertical-align: -0.838ex; width:50.759ex; height:2.843ex;"/>
  </span>
 </p>
 <p>
  where L and R represent the left ear and right ear respectively,
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle P_{L}}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           L
          </mi>
         </mrow>
        </msub>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle P_{L}}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle P_{L}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bbfa4c6ed25929d86a4f6d3e7ec3f37abc65b4b8" style="vertical-align: -0.671ex; width:2.844ex; height:2.509ex;"/>
  </span>
  and
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle P_{R}}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           R
          </mi>
         </mrow>
        </msub>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle P_{R}}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle P_{R}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9ea3ad403ba0657b26fe3634c927faf5a14c6f07" style="vertical-align: -0.671ex; width:2.972ex; height:2.509ex;"/>
  </span>
  represent the amplitude of the sound pressure at the entrances to the left and right ear canals, and
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle P_{0}}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          P
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mn>
           0
          </mn>
         </mrow>
        </msub>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle P_{0}}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle P_{0}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/671bd891701e0d6cfa6da0114a5dd64233b58709" style="vertical-align: -0.671ex; width:2.547ex; height:2.509ex;"/>
  </span>
  is the amplitude of sound pressure at the center of the head coordinate when listener does not exist. In general, an HRTF's
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle H_{L}}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           L
          </mi>
         </mrow>
        </msub>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle H_{L}}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle H_{L}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c69b3a99f93f7f8f8f39aca4e38a4c6347163a51" style="vertical-align: -0.671ex; width:3.283ex; height:2.509ex;"/>
  </span>
  and
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle H_{R}}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <msub>
         <mi>
          H
         </mi>
         <mrow class="MJX-TeXAtom-ORD">
          <mi>
           R
          </mi>
         </mrow>
        </msub>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle H_{R}}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle H_{R}}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f205c01228d401faa2f1ff85d0a518f8e322f2a2" style="vertical-align: -0.671ex; width:3.411ex; height:2.509ex;"/>
  </span>
  are functions of source angular position
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <mi>
         θ
         <!-- θ -->
        </mi>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle \theta }
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle \theta }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/>
  </span>
  , elevation angle
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle \varphi }" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <mi>
         φ
         <!-- φ -->
        </mi>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle \varphi }
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle \varphi }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33ee699558d09cf9d653f6351f9fda0b2f4aaa3e" style="vertical-align: -0.838ex; width:1.52ex; height:2.176ex;"/>
  </span>
  , the distance between the source and the center of the head
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle r}" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <mi>
         r
        </mi>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle r}
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle r}" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0d1ecb613aa2984f0576f70f86650b7c2a132538" style="vertical-align: -0.338ex; width:1.049ex; height:1.676ex;"/>
  </span>
  , the angular velocity
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle \omega }" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <mi>
         ω
         <!-- ω -->
        </mi>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle \omega }
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle \omega }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/48eff443f9de7a985bb94ca3bde20813ea737be8" style="vertical-align: -0.338ex; width:1.446ex; height:1.676ex;"/>
  </span>
  and the equivalent dimension of the head
  <span class="mwe-math-element">
   <span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;">
    <math alttext="{\displaystyle \alpha }" xmlns="http://www.w3.org/1998/Math/MathML">
     <semantics>
      <mrow class="MJX-TeXAtom-ORD">
       <mstyle displaystyle="true" scriptlevel="0">
        <mi>
         α
         <!-- α -->
        </mi>
       </mstyle>
      </mrow>
      <annotation encoding="application/x-tex">
       {\displaystyle \alpha }
      </annotation>
     </semantics>
    </math>
   </span>
   <img alt="{\displaystyle \alpha }" aria-hidden="true" class="mwe-math-fallback-image-inline mw-invert skin-invert" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3" style="vertical-align: -0.338ex; width:1.488ex; height:1.676ex;"/>
  </span>
  .
 </p>
 <p>
  At present, the main institutes that work on measuring HRTF database include CIPIC
  <sup class="reference" id="cite_ref-17">
   <a href="#cite_note-17">
    [17]
   </a>
  </sup>
  International Lab, MIT Media Lab, the Graduate School in Psychoacoustics at the University of Oldenburg, the Neurophysiology Lab at the University of Wisconsin–Madison and Ames Lab of NASA. Databases of HRIRs from humans with normal and impaired hearing and from animals are publicly available.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Other_cues">
   Other cues
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=6" title="Edit section: Other cues">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  The human
  <a href="/wiki/Outer_ear" title="Outer ear">
   outer ear
  </a>
  , i.e. the structures of the
  <a class="mw-redirect" href="/wiki/Pinna_(anatomy)" title="Pinna (anatomy)">
   pinna
  </a>
  and the external
  <a href="/wiki/Ear_canal" title="Ear canal">
   ear canal
  </a>
  , form direction-selective filters. Depending on the sound input direction, different filter resonances become active. These resonances implant direction-specific patterns into the
  <a href="/wiki/Frequency_response" title="Frequency response">
   frequency responses
  </a>
  of the ears, which can be evaluated by the
  <a href="/wiki/Auditory_system" title="Auditory system">
   auditory system
  </a>
  for sound localization. Together with other direction-selective reflections at the head, shoulders and torso, they form the outer ear transfer functions. These patterns in the ear's
  <a href="/wiki/Frequency_response" title="Frequency response">
   frequency responses
  </a>
  are highly individual, depending on the shape and size of the outer ear. If sound is presented through headphones, and has been recorded via another head with different-shaped outer ear surfaces, the directional patterns differ from the listener's own, and problems will appear when trying to evaluate directions in the median plane with these foreign ears. As a consequence, front–back permutations or inside-the-head-localization can appear when listening to
  <a class="mw-redirect" href="/wiki/Dummy_head_recording" title="Dummy head recording">
   dummy head recordings
  </a>
  , or otherwise referred to as binaural recordings. It has been shown that human subjects can monaurally localize high frequency sound but not low frequency sound. Binaural localization, however, was possible with lower frequencies. This is likely due to the pinna being small enough to only interact with sound waves of high frequency.
  <sup class="reference" id="cite_ref-18">
   <a href="#cite_note-18">
    [18]
   </a>
  </sup>
  It seems that people can only accurately localize the elevation of sounds that are complex and include frequencies above 7,000 Hz, and a pinna must be present.
  <sup class="reference" id="cite_ref-19">
   <a href="#cite_note-19">
    [19]
   </a>
  </sup>
 </p>
 <p>
  When the head is stationary, the binaural cues for lateral sound localization (interaural time difference and interaural level difference) do not give information about the location of a sound in the median plane. Identical ITDs and ILDs can be produced by sounds at eye level or at any elevation, as long as the lateral direction is constant. However, if the head is rotated, the ITD and ILD change dynamically, and those changes are different for sounds at different elevations. For example, if an eye-level sound source is straight ahead and the head turns to the left, the sound becomes louder (and arrives sooner) at the right ear than at the left. But if the sound source is directly overhead, there will be no change in the ITD and ILD as the head turns. Intermediate elevations will produce intermediate degrees of change, and if the presentation of binaural cues to the two ears during head movement is reversed, the sound will be heard behind the listener.
  <sup class="reference" id="cite_ref-HW1940_13-1">
   <a href="#cite_note-HW1940-13">
    [13]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-20">
   <a href="#cite_note-20">
    [20]
   </a>
  </sup>
  <a href="/wiki/Hans_Wallach" title="Hans Wallach">
   Hans Wallach
  </a>
  <sup class="reference" id="cite_ref-21">
   <a href="#cite_note-21">
    [21]
   </a>
  </sup>
  artificially altered a sound's binaural cues during movements of the head. Although the sound was objectively placed at eye level, the dynamic changes to ITD and ILD as the head rotated were those that would be produced if the sound source had been elevated. In this situation, the sound was heard at the synthesized elevation. The fact that the sound sources objectively remained at eye level prevented monaural cues from specifying the elevation, showing that it was the dynamic change in the binaural cues during head movement that allowed the sound to be correctly localized in the vertical dimension. The head movements need not be actively produced; accurate vertical localization occurred in a similar setup when the head rotation was produced passively, by seating the blindfolded subject in a rotating chair. As long as the dynamic changes in binaural cues accompanied a perceived head rotation, the synthesized elevation was perceived.
  <sup class="reference" id="cite_ref-HW1940_13-2">
   <a href="#cite_note-HW1940-13">
    [13]
   </a>
  </sup>
 </p>
 <p>
  In the 1960s
  <a href="/wiki/Dwight_Wayne_Batteau" title="Dwight Wayne Batteau">
   Batteau
  </a>
  showed the pinna also enhances horizontal localization.
  <sup class="reference" id="cite_ref-nweek_22-0">
   <a href="#cite_note-nweek-22">
    [22]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-roy_23-0">
   <a href="#cite_note-roy-23">
    [23]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Distance_of_the_sound_source">
   Distance of the sound source
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=7" title="Edit section: Distance of the sound source">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  <sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">
   [
   <i>
    <a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">
     <span title="This claim needs references to reliable sources. (March 2019)">
      citation needed
     </span>
    </a>
   </i>
   ]
  </sup>
 </p>
 <p>
  The human auditory system has only limited possibilities to determine the distance of a sound source. In the close-up-range there are some indications for distance determination, such as extreme level differences (e.g. when whispering into one ear) or specific
  <a class="mw-redirect" href="/wiki/Pinna_(anatomy)" title="Pinna (anatomy)">
   pinna
  </a>
  (the visible part of the ear) resonances in the close-up range.
 </p>
 <p>
  The auditory system uses these clues to estimate the distance to a sound source:
 </p>
 <ul>
  <li>
   Direct/ Reflection ratio: In enclosed rooms, two types of sound are arriving at a listener: The direct sound arrives at the listener's ears without being reflected at a wall. Reflected sound has been reflected at least one time at a wall before arriving at the listener. The ratio between direct sound and reflected sound can give an indication about the distance of the sound source.
  </li>
  <li>
   Loudness: Distant sound sources have a lower loudness than close ones. This aspect can be evaluated especially for well-known sound sources.
  </li>
  <li>
   Sound spectrum: High frequencies are more quickly damped by the air than low frequencies. Therefore, a distant sound source sounds more muffled than a close one, because the high frequencies are attenuated. For sound with a known spectrum (e.g. speech) the distance can be estimated roughly with the help of the perceived sound.
  </li>
  <li>
   ITDG: The Initial Time Delay Gap describes the time difference between arrival of the direct wave and first strong reflection at the listener. Nearby sources create a relatively large ITDG, with the first reflections having a longer path to take, possibly many times longer. When the source is far away, the direct and the reflected sound waves have similar path lengths.
  </li>
  <li>
   Movement: Similar to the visual system there is also the phenomenon of motion
   <a href="/wiki/Parallax" title="Parallax">
    parallax
   </a>
   in acoustical perception. For a moving listener nearby sound sources are passing faster than distant sound sources.
  </li>
  <li>
   Level Difference: Very close sound sources cause a different level between the ears.
  </li>
 </ul>
 <div class="mw-heading mw-heading3">
  <h3 id="Signal_processing">
   Signal processing
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=8" title="Edit section: Signal processing">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Sound processing of the human auditory system is performed in so-called
  <a href="/wiki/Critical_band" title="Critical band">
   critical bands
  </a>
  . The
  <a href="/wiki/Hearing_range" title="Hearing range">
   hearing range
  </a>
  is segmented into 24 critical bands, each with a width of 1
  <a href="/wiki/Bark_scale" title="Bark scale">
   Bark
  </a>
  or 100
  <a href="/wiki/Mel_scale" title="Mel scale">
   Mel
  </a>
  . For a directional analysis the signals inside the critical band are analyzed together.
 </p>
 <p>
  The auditory system can extract the sound of a desired sound source out of interfering noise. This allows the listener to concentrate on only one speaker if other speakers are also talking (the
  <a href="/wiki/Cocktail_party_effect" title="Cocktail party effect">
   cocktail party effect
  </a>
  ). With the help of the cocktail party effect sound from interfering directions is perceived attenuated compared to the sound from the desired direction. The auditory system can increase the
  <a href="/wiki/Signal-to-noise_ratio" title="Signal-to-noise ratio">
   signal-to-noise ratio
  </a>
  by up to 15
  <a href="/wiki/Decibel" title="Decibel">
   dB
  </a>
  , which means that interfering sound is perceived to be attenuated to half (or less) of its actual
  <a href="/wiki/Loudness" title="Loudness">
   loudness
  </a>
  .
  <sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">
   [
   <i>
    <a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">
     <span title="This claim needs references to reliable sources. (September 2013)">
      citation needed
     </span>
    </a>
   </i>
   ]
  </sup>
 </p>
 <p>
  In enclosed rooms not only the direct sound from a sound source is arriving at the listener's ears, but also sound which has been
  <a href="/wiki/Reflection_(physics)" title="Reflection (physics)">
   reflected
  </a>
  at the walls. The auditory system analyses only the direct sound,
  <sup class="reference" id="cite_ref-WNR_12-1">
   <a href="#cite_note-WNR-12">
    [12]
   </a>
  </sup>
  which is arriving first, for sound localization, but not the reflected sound, which is arriving later (
  <a href="/wiki/Precedence_effect" title="Precedence effect">
   law of the first wave front
  </a>
  ). So sound localization remains possible even in an echoic environment. This echo cancellation occurs in the Dorsal Nucleus of the
  <a class="mw-redirect" href="/wiki/Lateral_Lemniscus" title="Lateral Lemniscus">
   Lateral Lemniscus
  </a>
  (DNLL).
  <sup class="reference" id="cite_ref-24">
   <a href="#cite_note-24">
    [24]
   </a>
  </sup>
 </p>
 <p>
  In order to determine the time periods, where the direct sound prevails and which can be used for directional evaluation, the auditory system analyzes loudness changes in different critical bands and also the stability of the perceived direction. If there is a strong attack of the loudness in several critical bands and if the perceived direction is stable, this attack is in all probability caused by the direct sound of a sound source, which is entering newly or which is changing its signal characteristics. This short time period is used by the auditory system for directional and loudness analysis of this sound. When reflections arrive a little bit later, they do not enhance the loudness inside the critical bands in such a strong way, but the directional cues become unstable, because there is a mix of sound of several reflection directions. As a result, no new directional analysis is triggered by the auditory system.
 </p>
 <p>
  This first detected direction from the direct sound is taken as the found sound source direction, until other strong loudness attacks, combined with stable directional information, indicate that a new directional analysis is possible. (see
  <a href="/wiki/Franssen_effect" title="Franssen effect">
   Franssen effect
  </a>
  )
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Specific_techniques_with_applications">
   Specific techniques with applications
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=9" title="Edit section: Specific techniques with applications">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <div class="mw-heading mw-heading3">
  <h3 id="Auditory_transmission_stereo_system">
   Auditory transmission stereo system
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=10" title="Edit section: Auditory transmission stereo system">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  This kind of sound localization technique provides us the real virtual
  <a class="mw-redirect" href="/wiki/Stereo_system" title="Stereo system">
   stereo system
  </a>
  .
  <sup class="reference" id="cite_ref-:1_25-0">
   <a href="#cite_note-:1-25">
    [25]
   </a>
  </sup>
  It utilizes "smart" manikins, such as KEMAR,  to glean signals or use DSP methods to simulate the transmission process from sources to ears. After amplifying, recording and transmitting, the two channels of received signals will be reproduced through earphones or speakers.  This localization approach uses electroacoustic methods to obtain the spatial information of the original sound field by transferring the listener's auditory apparatus to the original sound field. The most considerable advantages of it would be that its acoustic images are lively and natural. Also, it only needs two independent transmitted signals to reproduce the acoustic image of a 3D system.
 </p>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:Research04_img_00L.jpg">
   <img class="mw-file-element" data-file-height="149" data-file-width="309" decoding="async" height="106" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Research04_img_00L.jpg/220px-Research04_img_00L.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/a/a2/Research04_img_00L.jpg 1.5x" width="220"/>
  </a>
  <figcaption>
   Sound localization with manikin
  </figcaption>
 </figure>
 <div class="mw-heading mw-heading3">
  <h3 id="3D_para-virtualization_stereo_system">
   3D para-virtualization stereo system
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=11" title="Edit section: 3D para-virtualization stereo system">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  The representatives of this kind of system are SRS Audio Sandbox, Spatializer Audio Lab and
  <a href="/wiki/QSound" title="QSound">
   Qsound
  </a>
  Qxpander.
  <sup class="reference" id="cite_ref-:1_25-1">
   <a href="#cite_note-:1-25">
    [25]
   </a>
  </sup>
  They use HRTF to simulate the received acoustic signals at the ears from different directions with common binary-channel stereo reproduction. Therefore, they can simulate reflected sound waves and improve subjective sense of space and envelopment. Since they are para-virtualization stereo systems, the major goal of them is to simulate stereo sound information.  Traditional stereo systems use sensors that are quite different from human ears. Although those sensors can receive the acoustic information from different directions, they do not have the same frequency response of human auditory system. Therefore, when binary-channel mode is applied, human auditory systems still cannot feel the 3D sound effect field. However, the 3D para-virtualization stereo system overcome such disadvantages. It uses HRTF principles to glean acoustic information from the original sound field then produce a lively 3D sound field through common earphones or speakers.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Multichannel_stereo_virtual_reproduction">
   Multichannel stereo virtual reproduction
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=12" title="Edit section: Multichannel stereo virtual reproduction">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Since the multichannel stereo systems require many reproduction channels, some researchers adopted the HRTF simulation technologies to reduce the number of reproduction channels.
  <sup class="reference" id="cite_ref-:1_25-2">
   <a href="#cite_note-:1-25">
    [25]
   </a>
  </sup>
  They use only two speakers to simulate multiple speakers in a multichannel system. This process is called as virtual reproduction. Essentially, such approach uses both interaural difference principle and pinna filtering effect theory.  Unfortunately, this kind of approach cannot perfectly substitute the traditional multichannel stereo system, such as
  <a class="mw-redirect" href="/wiki/5.1" title="5.1">
   5.1
  </a>
  /
  <a href="/wiki/7.1_surround_sound" title="7.1 surround sound">
   7.1 surround sound
  </a>
  system. That is because when the listening zone is relatively larger, simulation reproduction through HRTFs may cause invert acoustic images at symmetric positions.
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Animals">
   Animals
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=13" title="Edit section: Animals">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Since most animals have two ears, many of the effects of the human auditory system can also be found in other animals. Therefore, interaural time differences (interaural phase differences) and interaural level differences play a role for the hearing of many animals. But the influences on localization of these effects are dependent on head sizes, ear distances, the ear positions and the orientation of the ears.  Smaller animals like insects use different techniques as the separation of the ears are too small.
  <sup class="reference" id="cite_ref-26">
   <a href="#cite_note-26">
    [26]
   </a>
  </sup>
  For the process of animals emitting sound to improve localization, a biological form of
  <a class="mw-redirect" href="/wiki/Active_sonar" title="Active sonar">
   active sonar
  </a>
  , see
  <a href="/wiki/Animal_echolocation" title="Animal echolocation">
   animal echolocation
  </a>
  .
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Lateral_information_(left,_ahead,_right)">
   <span id="Lateral_information_.28left.2C_ahead.2C_right.29">
   </span>
   Lateral information (left, ahead, right)
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=14" title="Edit section: Lateral information (left, ahead, right)">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  If the ears are located at the side of the head, similar lateral localization cues as for the human auditory system can be used. This means: evaluation of
  <a href="/wiki/Interaural_time_difference" title="Interaural time difference">
   interaural time differences
  </a>
  (interaural phase differences) for lower frequencies and evaluation of interaural level differences for higher frequencies. The evaluation of interaural phase differences is useful, as long as it gives unambiguous results. This is the case, as long as ear distance is smaller than half the length (maximal one wavelength) of the sound waves. For animals with a larger head than humans the evaluation range for interaural phase differences is shifted towards lower frequencies, for animals with a smaller head, this range is shifted towards higher frequencies.
 </p>
 <p>
  The lowest frequency which can be localized depends on the ear distance. Animals with a greater ear distance can localize lower frequencies than humans can. For animals with a smaller ear distance the lowest localizable frequency is higher than for humans.
 </p>
 <p>
  If the ears are located at the side of the head, interaural level differences appear for higher frequencies and can be evaluated for localization tasks. For animals with ears at the top of the head, no shadowing by the head will appear and therefore there will be much less interaural level differences, which could be evaluated. Many of these animals can move their ears, and these ear movements can be used as a lateral localization cue.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="In_the_median_plane_(front,_above,_back,_below)">
   <span id="In_the_median_plane_.28front.2C_above.2C_back.2C_below.29">
   </span>
   In the median plane (front, above, back, below)
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=15" title="Edit section: In the median plane (front, above, back, below)">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  For many mammals there are also pronounced structures in the pinna near the entry of the ear canal. As a consequence, direction-dependent resonances can appear, which could be used as an additional localization cue, similar to the localization in the median plane in the human auditory system.
There are additional localization cues which are also used by animals.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Head_tilting">
   Head tilting
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=16" title="Edit section: Head tilting">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  For sound localization in the median plane (elevation of the sound) also two detectors can be used, which are positioned at different heights. In animals, however, rough elevation information is gained simply by tilting the head, provided that the sound lasts long enough to complete the movement. This explains the innate behavior of
  <sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">
   [
   <i>
    <a href="/wiki/Wikipedia:Vagueness" title="Wikipedia:Vagueness">
     <span title="This information is too vague. (December 2013)">
      vague
     </span>
    </a>
   </i>
   ]
  </sup>
  cocking the head to one side when trying to localize a sound precisely. To get instantaneous localization in more than two dimensions from time-difference or amplitude-difference cues requires more than two detectors.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Localization_with_coupled_ears_(flies)">
   <span id="Localization_with_coupled_ears_.28flies.29">
   </span>
   Localization with coupled ears (flies)
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=17" title="Edit section: Localization with coupled ears (flies)">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  The tiny parasitic fly
  <i>
   <a href="/wiki/Ormia_ochracea" title="Ormia ochracea">
    Ormia ochracea
   </a>
  </i>
  has become a
  <a href="/wiki/Model_organism" title="Model organism">
   model organism
  </a>
  in sound localization experiments because of its unique
  <a href="/wiki/Ear" title="Ear">
   ear
  </a>
  . The animal is too small for the time difference of sound arriving at the two ears to be calculated in the usual way, yet it can determine the direction of sound sources with exquisite precision. The
  <a class="mw-redirect" href="/wiki/Tympanic_membrane" title="Tympanic membrane">
   tympanic membranes
  </a>
  of opposite ears are directly connected mechanically, allowing resolution of sub-microsecond time differences
  <sup class="reference" id="cite_ref-27">
   <a href="#cite_note-27">
    [27]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-28">
   <a href="#cite_note-28">
    [28]
   </a>
  </sup>
  and requiring a new
  <a href="/wiki/Neural_coding" title="Neural coding">
   neural coding
  </a>
  strategy.
  <sup class="reference" id="cite_ref-29">
   <a href="#cite_note-29">
    [29]
   </a>
  </sup>
  Ho
  <sup class="reference" id="cite_ref-30">
   <a href="#cite_note-30">
    [30]
   </a>
  </sup>
  showed that the coupled-eardrum system in frogs can produce increased interaural vibration disparities when only small
  <a class="mw-redirect" href="/wiki/Arrival_time" title="Arrival time">
   arrival time
  </a>
  and sound level differences were available to the animal's head. Efforts to build directional microphones based on the coupled-eardrum structure are underway.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Bi-coordinate_sound_localization_(owls)">
   <span id="Bi-coordinate_sound_localization_.28owls.29">
   </span>
   Bi-coordinate sound localization (owls)
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=18" title="Edit section: Bi-coordinate sound localization (owls)">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <link href="mw-data:TemplateStyles:r1236090951" rel="mw-deduplicated-inline-style"/>
 <div class="hatnote navigation-not-searchable" role="note">
  Main article:
  <a href="/wiki/Sound_localization_in_owls" title="Sound localization in owls">
   Sound localization in owls
  </a>
 </div>
 <p>
  Most owls are
  <a class="mw-redirect" href="/wiki/Nocturnal" title="Nocturnal">
   nocturnal
  </a>
  or
  <a class="mw-redirect" href="/wiki/Crepuscular" title="Crepuscular">
   crepuscular
  </a>
  <a class="mw-redirect" href="/wiki/Birds_of_prey" title="Birds of prey">
   birds of prey
  </a>
  . Because they hunt at night, they must rely on non-visual senses. Experiments by Roger Payne
  <sup class="reference" id="cite_ref-31">
   <a href="#cite_note-31">
    [31]
   </a>
  </sup>
  have shown that owls are sensitive to the sounds made by their prey, not the heat or the smell. In fact, the sound cues are both necessary and sufficient for localization of mice from a distant location where they are perched. For this to work, the owls must be able to accurately localize both the azimuth and the elevation of the sound source.
 </p>
 <div class="mw-heading mw-heading3">
  <h3 id="Dolphins">
   Dolphins
  </h3>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=19" title="Edit section: Dolphins">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  <a class="mw-redirect" href="/wiki/Dolphins" title="Dolphins">
   Dolphins
  </a>
  (and other
  <a class="mw-redirect" href="/wiki/Odontocetes" title="Odontocetes">
   odontocetes
  </a>
  ) rely on
  <a href="/wiki/Animal_echolocation" title="Animal echolocation">
   echolocation
  </a>
  to aid in detecting, identifying, localizing, and capturing prey. Dolphin sonar signals are well suited for localizing multiple, small targets in a three-dimensional aquatic environment by utilizing highly directional (3 dB beamwidth of about 10 deg), broadband (3 dB bandwidth typically of about 40 kHz; peak frequencies between 40 kHz and 120 kHz), short duration clicks (about 40 μs). Dolphins can localize sounds both passively and actively (echolocation) with a resolution of about 1 deg. Cross-modal matching (between vision and echolocation) suggests dolphins perceive the spatial structure of complex objects interrogated through echolocation, a feat that likely requires spatially resolving individual object features and integration into a holistic representation of object shape. Although dolphins are sensitive to small, binaural intensity and time differences, mounting evidence suggests dolphins employ position-dependent spectral cues derived from well-developed head-related transfer functions, for sound localization in both the horizontal and vertical planes. A very small temporal integration time (264 μs) allows localization of multiple targets at varying distances. Localization adaptations include pronounced asymmetry of the skull, nasal sacks, and specialized lipid structures in the forehead and jaws, as well as acoustically isolated middle and inner ears.
 </p>
 <p>
  <b>
   The role of Prestin in sound localization:
  </b>
 </p>
 <p>
  In the realm of mammalian sound localization, the
  <a href="/wiki/Prestin" title="Prestin">
   Prestin
  </a>
  gene has emerged as a pivotal player, particularly in the fascinating arena of
  <a href="/wiki/Animal_echolocation" title="Animal echolocation">
   echolocation
  </a>
  employed by bats and dolphins. Discovered just over a decade ago, Prestin encodes a protein located in the inner ear's hair cells, facilitating rapid contractions and expansions. This intricate mechanism operates akin to an antique phonograph horn, amplifying sound waves within the cochlea and elevating the overall sensitivity of hearing.
 </p>
 <p>
  In 2014  Liu and others delved into the evolutionary adaptations of
  <a href="/wiki/Prestin" title="Prestin">
   Prestin
  </a>
  , unveiling its critical role in the ultrasonic hearing range essential for animal sonar, specifically in the context of
  <a href="/wiki/Animal_echolocation" title="Animal echolocation">
   echolocation
  </a>
  . This adaptation proves instrumental for dolphins navigating through turbid waters and bats seeking sustenance in nocturnal darkness.
  <sup class="reference" id="cite_ref-:2_32-0">
   <a href="#cite_note-:2-32">
    [32]
   </a>
  </sup>
 </p>
 <p>
  Noteworthy is the emission of high-frequency echolocation calls by toothed whales and echolocating bats, showcasing diversity in shape, duration, and amplitude. However, it is their high-frequency hearing that becomes paramount, as it enables the reception and analysis of echoes bouncing off objects in their environment. A meticulous dissection of Prestin protein function in sonar-guided bats and bottlenose dolphins, juxtaposed with nonsonar mammals, sheds light on the intricacies of this process.
 </p>
 <p>
  Evolutionary analyses of Prestin protein sequences brought forth a compelling observation – a singular
  <a href="/wiki/Amino_acid" title="Amino acid">
   amino acid
  </a>
  shift from threonine (Thr or T) in sonar mammals to asparagine (Asn or N) in nonsonar mammals. This specific alteration, subject to parallel evolution, emerges as a linchpin in the mammalian echolocation narrative.
  <sup class="reference" id="cite_ref-:2_32-1">
   <a href="#cite_note-:2-32">
    [32]
   </a>
  </sup>
 </p>
 <p>
  Subsequent experiments lent credence to this hypothesis, identifying four key
  <a href="/wiki/Amino_acid" title="Amino acid">
   amino acid
  </a>
  distinctions in sonar mammals that likely contribute to their distinctive echolocation features. The confluence of evolutionary analyses and empirical findings provides robust evidence, marking a significant juncture in comprehending the
  <a href="/wiki/Prestin" title="Prestin">
   Prestin
  </a>
  gene's role in the evolutionary trajectory of mammalian echolocation systems. This research underscores the adaptability and evolutionary significance of Prestin, offering valuable insights into the genetic foundations of sound localization in bats and dolphins, particularly within the sophisticated realm of echolocation.
  <sup class="reference" id="cite_ref-:2_32-2">
   <a href="#cite_note-:2-32">
    [32]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="History">
   History
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=20" title="Edit section: History">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  The term 'binaural' literally signifies 'to hear with two ears', and was introduced in 1859 to signify the practice of listening to the same sound through both ears, or to two discrete sounds, one through each ear. It was not until 1916 that
  <a href="/wiki/Carl_Stumpf" title="Carl Stumpf">
   Carl Stumpf
  </a>
  (1848–1936), a German
  <a href="/wiki/Philosophy" title="Philosophy">
   philosopher
  </a>
  and
  <a href="/wiki/Psychologist" title="Psychologist">
   psychologist
  </a>
  , distinguished between dichotic listening, which refers to the stimulation of each ear with a different
  <a href="/wiki/Stimulus_(physiology)" title="Stimulus (physiology)">
   stimulus
  </a>
  , and diotic listening, the simultaneous stimulation of both ears with the same stimulus.
  <sup class="reference" id="cite_ref-Wade2005_33-0">
   <a href="#cite_note-Wade2005-33">
    [33]
   </a>
  </sup>
 </p>
 <p>
  Later, it would become apparent that binaural hearing, whether dichotic or diotic, is the means by which sound localization occurs.
  <sup class="reference" id="cite_ref-Wade2005_33-1">
   <a href="#cite_note-Wade2005-33">
    [33]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-Beyer_34-0">
   <a href="#cite_note-Beyer-34">
    [34]
   </a>
  </sup>
  <sup class="noprint Inline-Template" style="white-space:nowrap;">
   [
   <i>
    <a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources">
     <span title="This citation requires a reference to the specific page or range of pages in which the material appears. (September 2017)">
      page needed
     </span>
    </a>
   </i>
   ]
  </sup>
 </p>
 <p>
  Scientific consideration of binaural hearing began before the phenomenon was so named, with speculations published in 1792 by
  <a href="/wiki/William_Charles_Wells" title="William Charles Wells">
   William Charles Wells
  </a>
  (1757–1817) based on his research into
  <a href="/wiki/Binocular_vision" title="Binocular vision">
   binocular vision
  </a>
  .
  <sup class="reference" id="cite_ref-Wade2008_35-0">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
  <a href="/wiki/Giovanni_Battista_Venturi" title="Giovanni Battista Venturi">
   Giovanni Battista Venturi
  </a>
  (1746–1822) conducted and described experiments in which people tried to localize a sound using both ears, or one ear blocked with a finger. This work was not followed up on, and was only recovered after others had worked out how human sound localization works.
  <sup class="reference" id="cite_ref-Wade2005_33-2">
   <a href="#cite_note-Wade2005-33">
    [33]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-Wade2008_35-1">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
  <a href="/wiki/John_William_Strutt,_3rd_Baron_Rayleigh" title="John William Strutt, 3rd Baron Rayleigh">
   Lord Rayleigh
  </a>
  (1842–1919) would do these same experiments and come to the results, without knowing Venturi had first done them, almost seventy-five years later.
  <sup class="reference" id="cite_ref-Wade2008_35-2">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
 </p>
 <p>
  <a href="/wiki/Charles_Wheatstone" title="Charles Wheatstone">
   Charles Wheatstone
  </a>
  (1802–1875) did work on optics and color mixing, and also explored hearing.  He invented a device he called a "microphone" that involved a metal plate over each ear, each connected to metal rods; he used this device to amplify sound.  He also did experiments holding
  <a href="/wiki/Tuning_fork" title="Tuning fork">
   tuning forks
  </a>
  to both ears at the same time, or separately, trying to work out how sense of hearing works, that he published in 1827.
  <sup class="reference" id="cite_ref-Wade2008_35-3">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
  <a href="/wiki/Ernst_Heinrich_Weber" title="Ernst Heinrich Weber">
   Ernst Heinrich Weber
  </a>
  (1795–1878) and
  <a href="/wiki/August_Seebeck" title="August Seebeck">
   August Seebeck
  </a>
  (1805–1849) and
  <a href="/wiki/William_Charles_Wells" title="William Charles Wells">
   William Charles Wells
  </a>
  also attempted to compare and contrast what would become known as binaural hearing with the principles of binocular integration generally.
  <sup class="reference" id="cite_ref-Wade2008_35-4">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
 </p>
 <p>
  Understanding how the differences in
  <a href="/wiki/Sound#Waves" title="Sound">
   sound signals
  </a>
  between two ears contributes to
  <a class="mw-redirect" href="/wiki/Auditory_processing" title="Auditory processing">
   auditory processing
  </a>
  in such a way as to enable sound localization and direction was considerably advanced after the invention of the
  <a class="mw-redirect" href="/wiki/Stethophone" title="Stethophone">
   stethophone
  </a>
  by
  <a class="new" href="/w/index.php?title=Somerville_Scott_Alison&amp;action=edit&amp;redlink=1" title="Somerville Scott Alison (page does not exist)">
   Somerville Scott Alison
  </a>
  in 1859, who coined the term 'binaural'. Alison based the stethophone on the
  <a href="/wiki/Stethoscope" title="Stethoscope">
   stethoscope
  </a>
  , which had been invented by
  <a href="/wiki/Ren%C3%A9_Laennec" title="René Laennec">
   René Théophile Hyacinthe Laennec
  </a>
  (1781–1826); the stethophone had two separate "pickups", allowing the user to hear and compare sounds derived from two discrete locations.
  <sup class="reference" id="cite_ref-Wade2008_35-5">
   <a href="#cite_note-Wade2008-35">
    [35]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="See_also">
   See also
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=21" title="Edit section: See also">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <ul>
  <li>
   <a href="/wiki/Acoustic_location" title="Acoustic location">
    Acoustic location
   </a>
  </li>
  <li>
   <a href="/wiki/Animal_echolocation" title="Animal echolocation">
    Animal echolocation
   </a>
  </li>
  <li>
   <a href="/wiki/Binaural_fusion" title="Binaural fusion">
    Binaural fusion
   </a>
  </li>
  <li>
   <a href="/wiki/Coincidence_detection_in_neurobiology" title="Coincidence detection in neurobiology">
    Coincidence detection in neurobiology
   </a>
  </li>
  <li>
   <a href="/wiki/Human_echolocation" title="Human echolocation">
    Human echolocation
   </a>
  </li>
  <li>
   <a href="/wiki/Perceptual-based_3D_sound_localization" title="Perceptual-based 3D sound localization">
    Perceptual-based 3D sound localization
   </a>
  </li>
  <li>
   <a href="/wiki/Psychoacoustics" title="Psychoacoustics">
    Psychoacoustics
   </a>
  </li>
  <li>
   <a href="/wiki/Spatial_hearing_loss" title="Spatial hearing loss">
    Spatial hearing loss
   </a>
  </li>
 </ul>
 <div class="mw-heading mw-heading2">
  <h2 id="References">
   References
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=22" title="Edit section: References">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <style data-mw-deduplicate="TemplateStyles:r1217336898">
  .mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}
 </style>
 <div class="reflist">
  <div class="mw-references-wrap mw-references-columns">
   <ol class="references">
    <li id="cite_note-1">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-1">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <style data-mw-deduplicate="TemplateStyles:r1215172403">
       .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a{background-size:contain}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a{background-size:contain}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a{background-size:contain}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#2C882D;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911F}html.skin-theme-clientpref-night .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-night .mw-parser-output .cs1-hidden-error{color:#f8a397}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-os .mw-parser-output .cs1-hidden-error{color:#f8a397}html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911F}}
      </style>
      <cite class="citation journal cs1" id="CITEREFJeffress_L.A.1948">
       Jeffress L.A. (1948). "A place theory of sound localization".
       <i>
        Journal of Comparative and Physiological Psychology
       </i>
       .
       <b>
        41
       </b>
       (1): 35–39.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1037%2Fh0061495" rel="nofollow">
        10.1037/h0061495
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/18904764" rel="nofollow">
        18904764
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Comparative+and+Physiological+Psychology&amp;rft.atitle=A+place+theory+of+sound+localization&amp;rft.volume=41&amp;rft.issue=1&amp;rft.pages=35-39&amp;rft.date=1948&amp;rft_id=info%3Adoi%2F10.1037%2Fh0061495&amp;rft_id=info%3Apmid%2F18904764&amp;rft.au=Jeffress+L.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-2">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-2">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Schnupp J., Nelken I &amp; King A.J., 2011. Auditory Neuroscience, MIT Press, chapter 5.
     </span>
    </li>
    <li id="cite_note-3">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-3">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Blauert, J.: Spatial hearing: the psychophysics of human sound localization; MIT Press; Cambridge, Massachusetts (1983)
     </span>
    </li>
    <li id="cite_note-Thompson-4">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-Thompson_4-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Thompson_4-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Thompson_4-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Thompson_4-3">
       <sup>
        <i>
         <b>
          d
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Thompson_4-4">
       <sup>
        <i>
         <b>
          e
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Thompson_4-5">
       <sup>
        <i>
         <b>
          f
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Thompson, Daniel M. Understanding Audio: Getting the Most out of Your Project or Professional Recording Studio. Boston, MA: Berklee, 2005. Print.
     </span>
    </li>
    <li id="cite_note-Roads-5">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-Roads_5-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Roads_5-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Roads_5-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Roads, Curtis. The Computer Music Tutorial. Cambridge, MA: MIT, 2007. Print.
     </span>
    </li>
    <li id="cite_note-Benade-6">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-Benade_6-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Benade_6-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Benade, Arthur H. Fundamentals of Musical Acoustics. New York: Oxford UP, 1976. Print.
     </span>
    </li>
    <li id="cite_note-7">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-7">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Rayleigh L. XII. On our perception of sound direction[J]. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 1907, 13(74): 214-232.
     </span>
    </li>
    <li id="cite_note-:0-8">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-:0_8-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:0_8-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:0_8-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Zhou X. Virtual reality technique[J]. Telecommunications Science, 1996, 12(7): 46-–.
     </span>
    </li>
    <li id="cite_note-9">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-9">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation web cs1" id="CITEREFIan_Pitt">
       Ian Pitt.
       <a class="external text" href="https://web.archive.org/web/20100410235208/http://www.cs.ucc.ie/~ianp/CS2511/HAP.html" rel="nofollow">
        "Auditory Perception"
       </a>
       . Archived from
       <a class="external text" href="http://www.cs.ucc.ie/~ianp/CS2511/HAP.html" rel="nofollow">
        the original
       </a>
       on 2010-04-10.
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Auditory+Perception&amp;rft.au=Ian+Pitt&amp;rft_id=http%3A%2F%2Fwww.cs.ucc.ie%2F~ianp%2FCS2511%2FHAP.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-10">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-10">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation book cs1" id="CITEREFDeLiang_WangGuy_J._Brown2006">
       DeLiang Wang; Guy J. Brown (2006).
       <i>
        Computational auditory scene analysis: principles, algorithms and applications
       </i>
       . Wiley interscience.
       <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">
        ISBN
       </a>
       <a href="/wiki/Special:BookSources/9780471741091" title="Special:BookSources/9780471741091">
        <bdi>
         9780471741091
        </bdi>
       </a>
       .
       <q>
        For sinusoidal signals presented on the horizontal plane, spatial resolution is highest for sounds coming from the median plane (directly in front of the listener) with about 1 degree MAA, and it deteriorates markedly when stimuli are moved to the side – e.g., the MAA is about 7 degrees for sounds originating at 75 degrees to the side.
       </q>
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computational+auditory+scene+analysis%3A+principles%2C+algorithms+and+applications&amp;rft.pub=Wiley+interscience&amp;rft.date=2006&amp;rft.isbn=9780471741091&amp;rft.au=DeLiang+Wang&amp;rft.au=Guy+J.+Brown&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-11">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-11">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <a class="external text" href="http://acousticslab.org/psychoacoustics/PMFiles/Module07a.htm" rel="nofollow">
       Auditory localization - Introduction
      </a>
      <i>
       Columbia College, Chicago - Audio Arts &amp; Acoustics acousticslab.org/psychoacoustics
      </i>
      , accessed 16 May 2021
     </span>
    </li>
    <li id="cite_note-WNR-12">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-WNR_12-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-WNR_12-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWallachNewman,_E.B.Rosenzweig,_M.R.1949">
       Wallach, H; Newman, E.B.; Rosenzweig, M.R. (July 1949). "The precedence effect in sound localization".
       <i>
        American Journal of Psychology
       </i>
       .
       <b>
        62
       </b>
       (3): 315–336.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.2307%2F1418275" rel="nofollow">
        10.2307/1418275
       </a>
       .
       <a class="mw-redirect" href="/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">
        JSTOR
       </a>
       <a class="external text" href="https://www.jstor.org/stable/1418275" rel="nofollow">
        1418275
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/18134356" rel="nofollow">
        18134356
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=American+Journal+of+Psychology&amp;rft.atitle=The+precedence+effect+in+sound+localization&amp;rft.volume=62&amp;rft.issue=3&amp;rft.pages=315-336&amp;rft.date=1949-07&amp;rft_id=info%3Apmid%2F18134356&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F1418275%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.2307%2F1418275&amp;rft.aulast=Wallach&amp;rft.aufirst=H&amp;rft.au=Newman%2C+E.B.&amp;rft.au=Rosenzweig%2C+M.R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-HW1940-13">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-HW1940_13-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-HW1940_13-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-HW1940_13-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWallach1940">
       Wallach, Hans (October 1940). "The role of head movements and vestibular and visual cues in sound localization".
       <i>
        Journal of Experimental Psychology
       </i>
       .
       <b>
        27
       </b>
       (4): 339–368.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1037%2Fh0054629" rel="nofollow">
        10.1037/h0054629
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology&amp;rft.atitle=The+role+of+head+movements+and+vestibular+and+visual+cues+in+sound+localization&amp;rft.volume=27&amp;rft.issue=4&amp;rft.pages=339-368&amp;rft.date=1940-10&amp;rft_id=info%3Adoi%2F10.1037%2Fh0054629&amp;rft.aulast=Wallach&amp;rft.aufirst=Hans&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-nw61-14">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-nw61_14-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation magazine cs1">
       "Acoustics: The Ears Have It".
       <i>
        Newsweek
       </i>
       . 1961-12-04. p. 80.
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Newsweek&amp;rft.atitle=Acoustics%3A+The+Ears+Have+It&amp;rft.pages=80&amp;rft.date=1961-12-04&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-15">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-15">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Batteau D W. The role of the pinna in human localization[J]. Proceedings of the Royal Society of London B: Biological Sciences, 1967, 168(1011): 158-180.
     </span>
    </li>
    <li id="cite_note-16">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-16">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Musicant A D, Butler R A. The influence of pinnae-based spectral cues on sound localization[J]. The Journal of the Acoustical Society of America, 1984, 75(4): 1195–1200.
     </span>
    </li>
    <li id="cite_note-17">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-17">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation web cs1">
       <a class="external text" href="https://web.archive.org/web/20130913113821/http://interface.cipic.ucdavis.edu/sound/hrtf.html" rel="nofollow">
        "The CIPIC HRTF Database"
       </a>
       . Archived from
       <a class="external text" href="http://interface.cipic.ucdavis.edu/sound/hrtf.html" rel="nofollow">
        the original
       </a>
       on 2013-09-13.
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+CIPIC+HRTF+Database&amp;rft_id=http%3A%2F%2Finterface.cipic.ucdavis.edu%2Fsound%2Fhrtf.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-18">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-18">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFRobert_A._BUTLERRichard_A._HUMANSKI1992">
       Robert A. BUTLER; Richard A. HUMANSKI (1992).
       <a class="external text" href="https://doi.org/10.3758%2Fbf03212242" rel="nofollow">
        "Localization of sound in the vertical plane with and without high-frequency spectral cues"
       </a>
       .
       <i>
        Perception &amp; Psychophysics
       </i>
       .
       <b>
        51
       </b>
       (2): 182–186.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <span class="id-lock-free" title="Freely accessible">
        <a class="external text" href="https://doi.org/10.3758%2Fbf03212242" rel="nofollow">
         10.3758/bf03212242
        </a>
       </span>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/1549436" rel="nofollow">
        1549436
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Perception+%26+Psychophysics&amp;rft.atitle=Localization+of+sound+in+the+vertical+plane+with+and+without+high-frequency+spectral+cues&amp;rft.volume=51&amp;rft.issue=2&amp;rft.pages=182-186&amp;rft.date=1992&amp;rft_id=info%3Adoi%2F10.3758%2Fbf03212242&amp;rft_id=info%3Apmid%2F1549436&amp;rft.au=Robert+A.+BUTLER&amp;rft.au=Richard+A.+HUMANSKI&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.3758%252Fbf03212242&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-19">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-19">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFRoffler_Suzanne_K.Butler_Robert_A.1968">
       Roffler Suzanne K.; Butler Robert A. (1968).
       <a class="external text" href="http://asadl.org/jasa/resource/1/jasman/v43/i6/p1255_s1" rel="nofollow">
        "Factors That Influence the Localization of Sound in the Vertical Plane"
       </a>
       .
       <i>
        J. Acoust. Soc. Am
       </i>
       .
       <b>
        43
       </b>
       (6): 1255–1259.
       <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">
        Bibcode
       </a>
       :
       <a class="external text" href="https://ui.adsabs.harvard.edu/abs/1968ASAJ...43.1255R" rel="nofollow">
        1968ASAJ...43.1255R
       </a>
       .
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1121%2F1.1910976" rel="nofollow">
        10.1121/1.1910976
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/5659493" rel="nofollow">
        5659493
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J.+Acoust.+Soc.+Am.&amp;rft.atitle=Factors+That+Influence+the+Localization+of+Sound+in+the+Vertical+Plane&amp;rft.volume=43&amp;rft.issue=6&amp;rft.pages=1255-1259&amp;rft.date=1968&amp;rft_id=info%3Apmid%2F5659493&amp;rft_id=info%3Adoi%2F10.1121%2F1.1910976&amp;rft_id=info%3Abibcode%2F1968ASAJ...43.1255R&amp;rft.au=Roffler+Suzanne+K.&amp;rft.au=Butler+Robert+A.&amp;rft_id=http%3A%2F%2Fasadl.org%2Fjasa%2Fresource%2F1%2Fjasman%2Fv43%2Fi6%2Fp1255_s1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-20">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-20">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Thurlow, W.R. "Audition" in Kling, J.W. &amp; Riggs, L.A.,
      <i>
       Experimental Psychology
      </i>
      , 3rd edition, Holt Rinehart &amp; Winston, 1971,  pp. 267–268.
     </span>
    </li>
    <li id="cite_note-21">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-21">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWallach1939">
       Wallach, H (1939). "On sound localization".
       <i>
        Journal of the Acoustical Society of America
       </i>
       .
       <b>
        10
       </b>
       (4): 270–274.
       <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">
        Bibcode
       </a>
       :
       <a class="external text" href="https://ui.adsabs.harvard.edu/abs/1939ASAJ...10..270W" rel="nofollow">
        1939ASAJ...10..270W
       </a>
       .
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1121%2F1.1915985" rel="nofollow">
        10.1121/1.1915985
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Acoustical+Society+of+America&amp;rft.atitle=On+sound+localization&amp;rft.volume=10&amp;rft.issue=4&amp;rft.pages=270-274&amp;rft.date=1939&amp;rft_id=info%3Adoi%2F10.1121%2F1.1915985&amp;rft_id=info%3Abibcode%2F1939ASAJ...10..270W&amp;rft.aulast=Wallach&amp;rft.aufirst=H&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-nweek-22">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-nweek_22-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      "The Ears Have It,"
      <i>
       Newsweek
      </i>
      1961-12-04, pp.80-81
     </span>
    </li>
    <li id="cite_note-roy-23">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-roy_23-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation web cs1" id="CITEREFBatteau1964">
       Batteau, Dwight Wayne (January 1964).
       <a class="external text" href="https://apps.dtic.mil/sti/tr/pdf/AD0600151.pdf" rel="nofollow">
        "The role of the pinna in human localization"
       </a>
       <span class="cs1-format">
        (PDF)
       </span>
       .
       <i>
        Proceedings of the Royal Society of London, B Biological Sciences
       </i>
       <span class="reference-accessdate">
        . Retrieved
        <span class="nowrap">
         2023-11-30
        </span>
       </span>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Proceedings+of+the+Royal+Society+of+London%2C+B+Biological+Sciences&amp;rft.atitle=The+role+of+the+pinna+in+human+localization&amp;rft.date=1964-01&amp;rft.aulast=Batteau&amp;rft.aufirst=Dwight+Wayne&amp;rft_id=https%3A%2F%2Fapps.dtic.mil%2Fsti%2Ftr%2Fpdf%2FAD0600151.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-24">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-24">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFKiddKelly1996">
       Kidd, Sean A.; Kelly, Jack B. (1996-11-15).
       <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6578946" rel="nofollow">
        "Contribution of the Dorsal Nucleus of the Lateral Lemniscus to Binaural Responses in the Inferior Colliculus of the Rat: Interaural Time Delays"
       </a>
       .
       <i>
        The Journal of Neuroscience
       </i>
       .
       <b>
        16
       </b>
       (22): 7390–7397.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1523%2FJNEUROSCI.16-22-07390.1996" rel="nofollow">
        10.1523/JNEUROSCI.16-22-07390.1996
       </a>
       .
       <a class="mw-redirect" href="/wiki/ISSN_(identifier)" title="ISSN (identifier)">
        ISSN
       </a>
       <a class="external text" href="https://www.worldcat.org/issn/0270-6474" rel="nofollow">
        0270-6474
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">
        PMC
       </a>
       <span class="id-lock-free" title="Freely accessible">
        <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6578946" rel="nofollow">
         6578946
        </a>
       </span>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/8929445" rel="nofollow">
        8929445
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+Neuroscience&amp;rft.atitle=Contribution+of+the+Dorsal+Nucleus+of+the+Lateral+Lemniscus+to+Binaural+Responses+in+the+Inferior+Colliculus+of+the+Rat%3A+Interaural+Time+Delays&amp;rft.volume=16&amp;rft.issue=22&amp;rft.pages=7390-7397&amp;rft.date=1996-11-15&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC6578946%23id-name%3DPMC&amp;rft.issn=0270-6474&amp;rft_id=info%3Apmid%2F8929445&amp;rft_id=info%3Adoi%2F10.1523%2FJNEUROSCI.16-22-07390.1996&amp;rft.aulast=Kidd&amp;rft.aufirst=Sean+A.&amp;rft.au=Kelly%2C+Jack+B.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC6578946&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-:1-25">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-:1_25-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:1_25-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:1_25-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Zhao R. Study of Auditory Transmission Sound Localization System[D], University of Science and Technology of China, 2006.
     </span>
    </li>
    <li id="cite_note-26">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-26">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFDíaz-GarcíaReidJackson-CamargoWindmill2022">
       Díaz-García, Lara; Reid, Andrew; Jackson-Camargo, Joseph; Windmill, James F.C. (2022).
       <a class="external text" href="https://ieeexplore.ieee.org/document/9858635" rel="nofollow">
        "Towards a bio-inspired acoustic sensor: Achroia grisella's ear"
       </a>
       .
       <i>
        IEEE Sensors Journal
       </i>
       .
       <b>
        22
       </b>
       (18): 17746–17753.
       <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">
        Bibcode
       </a>
       :
       <a class="external text" href="https://ui.adsabs.harvard.edu/abs/2022ISenJ..2217746D" rel="nofollow">
        2022ISenJ..2217746D
       </a>
       .
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1109%2FJSEN.2022.3197841" rel="nofollow">
        10.1109/JSEN.2022.3197841
       </a>
       .
       <a class="mw-redirect" href="/wiki/ISSN_(identifier)" title="ISSN (identifier)">
        ISSN
       </a>
       <a class="external text" href="https://www.worldcat.org/issn/1558-1748" rel="nofollow">
        1558-1748
       </a>
       .
       <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">
        S2CID
       </a>
       <a class="external text" href="https://api.semanticscholar.org/CorpusID:252223827" rel="nofollow">
        252223827
       </a>
       <span class="reference-accessdate">
        . Retrieved
        <span class="nowrap">
         12 September
        </span>
        2022
       </span>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Sensors+Journal&amp;rft.atitle=Towards+a+bio-inspired+acoustic+sensor%3A+Achroia+grisella%27s+ear&amp;rft.volume=22&amp;rft.issue=18&amp;rft.pages=17746-17753&amp;rft.date=2022&amp;rft_id=info%3Adoi%2F10.1109%2FJSEN.2022.3197841&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A252223827%23id-name%3DS2CID&amp;rft.issn=1558-1748&amp;rft_id=info%3Abibcode%2F2022ISenJ..2217746D&amp;rft.aulast=D%C3%ADaz-Garc%C3%ADa&amp;rft.aufirst=Lara&amp;rft.au=Reid%2C+Andrew&amp;rft.au=Jackson-Camargo%2C+Joseph&amp;rft.au=Windmill%2C+James+F.C.&amp;rft_id=https%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F9858635&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-27">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-27">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFMilesRobertHoy1995">
       Miles RN, Robert D, Hoy RR (Dec 1995). "Mechanically coupled ears for directional hearing in the parasitoid fly Ormia ochracea".
       <i>
        J Acoust Soc Am
       </i>
       .
       <b>
        98
       </b>
       (6): 3059–70.
       <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">
        Bibcode
       </a>
       :
       <a class="external text" href="https://ui.adsabs.harvard.edu/abs/1995ASAJ...98.3059M" rel="nofollow">
        1995ASAJ...98.3059M
       </a>
       .
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1121%2F1.413830" rel="nofollow">
        10.1121/1.413830
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/8550933" rel="nofollow">
        8550933
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Acoust+Soc+Am&amp;rft.atitle=Mechanically+coupled+ears+for+directional+hearing+in+the+parasitoid+fly+Ormia+ochracea&amp;rft.volume=98&amp;rft.issue=6&amp;rft.pages=3059-70&amp;rft.date=1995-12&amp;rft_id=info%3Apmid%2F8550933&amp;rft_id=info%3Adoi%2F10.1121%2F1.413830&amp;rft_id=info%3Abibcode%2F1995ASAJ...98.3059M&amp;rft.aulast=Miles&amp;rft.aufirst=RN&amp;rft.au=Robert%2C+D&amp;rft.au=Hoy%2C+RR&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-28">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-28">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFRobertMilesHoy1996">
       Robert D, Miles RN, Hoy RR (1996). "Directional hearing by mechanical coupling in the parasitoid fly Ormia ochracea".
       <i>
        J Comp Physiol A
       </i>
       .
       <b>
        179
       </b>
       (1): 29–44.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1007%2FBF00193432" rel="nofollow">
        10.1007/BF00193432
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/8965258" rel="nofollow">
        8965258
       </a>
       .
       <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">
        S2CID
       </a>
       <a class="external text" href="https://api.semanticscholar.org/CorpusID:21452506" rel="nofollow">
        21452506
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Comp+Physiol+A&amp;rft.atitle=Directional+hearing+by+mechanical+coupling+in+the+parasitoid+fly+Ormia+ochracea&amp;rft.volume=179&amp;rft.issue=1&amp;rft.pages=29-44&amp;rft.date=1996&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A21452506%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F8965258&amp;rft_id=info%3Adoi%2F10.1007%2FBF00193432&amp;rft.aulast=Robert&amp;rft.aufirst=D&amp;rft.au=Miles%2C+RN&amp;rft.au=Hoy%2C+RR&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-29">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-29">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFMasonOshinskyHoy2001">
       Mason AC, Oshinsky ML, Hoy RR (Apr 2001). "Hyperacute directional hearing in a microscale auditory system".
       <i>
        Nature
       </i>
       .
       <b>
        410
       </b>
       (6829): 686–90.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1038%2F35070564" rel="nofollow">
        10.1038/35070564
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/11287954" rel="nofollow">
        11287954
       </a>
       .
       <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">
        S2CID
       </a>
       <a class="external text" href="https://api.semanticscholar.org/CorpusID:4370356" rel="nofollow">
        4370356
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=Hyperacute+directional+hearing+in+a+microscale+auditory+system&amp;rft.volume=410&amp;rft.issue=6829&amp;rft.pages=686-90&amp;rft.date=2001-04&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A4370356%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F11287954&amp;rft_id=info%3Adoi%2F10.1038%2F35070564&amp;rft.aulast=Mason&amp;rft.aufirst=AC&amp;rft.au=Oshinsky%2C+ML&amp;rft.au=Hoy%2C+RR&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-30">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-30">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFHoNarins2006">
       Ho CC, Narins PM (Apr 2006). "Directionality of the pressure-difference receiver ears in the northern leopard frog, Rana pipiens pipiens".
       <i>
        J Comp Physiol A
       </i>
       .
       <b>
        192
       </b>
       (4): 417–29.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1007%2Fs00359-005-0080-7" rel="nofollow">
        10.1007/s00359-005-0080-7
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/16380842" rel="nofollow">
        16380842
       </a>
       .
       <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">
        S2CID
       </a>
       <a class="external text" href="https://api.semanticscholar.org/CorpusID:5881898" rel="nofollow">
        5881898
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J+Comp+Physiol+A&amp;rft.atitle=Directionality+of+the+pressure-difference+receiver+ears+in+the+northern+leopard+frog%2C+Rana+pipiens+pipiens&amp;rft.volume=192&amp;rft.issue=4&amp;rft.pages=417-29&amp;rft.date=2006-04&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A5881898%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F16380842&amp;rft_id=info%3Adoi%2F10.1007%2Fs00359-005-0080-7&amp;rft.aulast=Ho&amp;rft.aufirst=CC&amp;rft.au=Narins%2C+PM&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-31">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-31">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      Payne, Roger S., 1962. How the Barn Owl Locates Prey by Hearing.
      <i>
       The Living Bird, First Annual of the Cornell Laboratory of Ornithology
      </i>
      , 151-159
     </span>
    </li>
    <li id="cite_note-:2-32">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-:2_32-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:2_32-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-:2_32-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      Liu, Z., Qi, F. Y., Zhou, X., Ren, H. Q., &amp; Shi, P. (2014). Parallel sites implicate functional convergence of the hearing gene prestin among echolocating mammals.
      <i>
       Molecular biology and evolution
      </i>
      ,
      <i>
       31
      </i>
      (9), 2415–2424.
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
       doi
      </a>
      :
      <a class="external text" href="https://doi.org/10.1093%2Fmolbev%2Fmsu194" rel="nofollow">
       10.1093/molbev/msu194
      </a>
     </span>
    </li>
    <li id="cite_note-Wade2005-33">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-Wade2005_33-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2005_33-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2005_33-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWadeOno2005">
       Wade, NJ; Ono, H (2005). "From dichoptic to dichotic: historical contrasts between binocular vision and binaural hearing".
       <i>
        Perception
       </i>
       .
       <b>
        34
       </b>
       (6): 645–68.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1068%2Fp5327" rel="nofollow">
        10.1068/p5327
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/16042189" rel="nofollow">
        16042189
       </a>
       .
       <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">
        S2CID
       </a>
       <a class="external text" href="https://api.semanticscholar.org/CorpusID:43674057" rel="nofollow">
        43674057
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Perception&amp;rft.atitle=From+dichoptic+to+dichotic%3A+historical+contrasts+between+binocular+vision+and+binaural+hearing.&amp;rft.volume=34&amp;rft.issue=6&amp;rft.pages=645-68&amp;rft.date=2005&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A43674057%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F16042189&amp;rft_id=info%3Adoi%2F10.1068%2Fp5327&amp;rft.aulast=Wade&amp;rft.aufirst=NJ&amp;rft.au=Ono%2C+H&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-Beyer-34">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-Beyer_34-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation book cs1" id="CITEREFBeyer1999">
       Beyer, Robert T. (1999).
       <i>
        Sounds of our times : two hundred years of acoustics
       </i>
       . New York: Springer.
       <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">
        ISBN
       </a>
       <a href="/wiki/Special:BookSources/978-0-387-98435-3" title="Special:BookSources/978-0-387-98435-3">
        <bdi>
         978-0-387-98435-3
        </bdi>
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Sounds+of+our+times+%3A+two+hundred+years+of+acoustics&amp;rft.place=New+York&amp;rft.pub=Springer&amp;rft.date=1999&amp;rft.isbn=978-0-387-98435-3&amp;rft.aulast=Beyer&amp;rft.aufirst=Robert+T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
    <li id="cite_note-Wade2008-35">
     <span class="mw-cite-backlink">
      ^
      <a href="#cite_ref-Wade2008_35-0">
       <sup>
        <i>
         <b>
          a
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2008_35-1">
       <sup>
        <i>
         <b>
          b
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2008_35-2">
       <sup>
        <i>
         <b>
          c
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2008_35-3">
       <sup>
        <i>
         <b>
          d
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2008_35-4">
       <sup>
        <i>
         <b>
          e
         </b>
        </i>
       </sup>
      </a>
      <a href="#cite_ref-Wade2008_35-5">
       <sup>
        <i>
         <b>
          f
         </b>
        </i>
       </sup>
      </a>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWadeDeutsch2008">
       Wade, Nicholas J.; Deutsch, Diana (July 2008).
       <a class="external text" href="http://acousticstoday.org/wp-content/uploads/2017/07/Article_2of3_from_ATCODK_4_3.pdf" rel="nofollow">
        "Binaural Hearing—Before and After the Stethophone"
       </a>
       <span class="cs1-format">
        (PDF)
       </span>
       .
       <i>
        Acoustics Today
       </i>
       .
       <b>
        4
       </b>
       (3): 16–27.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1121%2F1.2994724" rel="nofollow">
        10.1121/1.2994724
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Acoustics+Today&amp;rft.atitle=Binaural+Hearing%E2%80%94Before+and+After+the+Stethophone&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=16-27&amp;rft.date=2008-07&amp;rft_id=info%3Adoi%2F10.1121%2F1.2994724&amp;rft.aulast=Wade&amp;rft.aufirst=Nicholas+J.&amp;rft.au=Deutsch%2C+Diana&amp;rft_id=http%3A%2F%2Facousticstoday.org%2Fwp-content%2Fuploads%2F2017%2F07%2FArticle_2of3_from_ATCODK_4_3.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASound+localization">
      </span>
     </span>
    </li>
   </ol>
  </div>
 </div>
 <div class="mw-heading mw-heading2">
  <h2 id="External_links">
   External links
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Sound_localization&amp;action=edit&amp;section=23" title="Edit section: External links">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <ul>
  <li>
   <a class="external text" href="https://archive.today/20121223103803/https://mustelid.physiol.ox.ac.uk/drupal/?q=spatial_hearing" rel="nofollow">
    auditoryneuroscience.com: Collection of multimedia files and flash demonstrations related to spatial hearing
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.pa.msu.edu/acoustics/loc.htm" rel="nofollow">
    Collection of references about sound localization
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.archive.org/web/20080427010049/http://www.ima.umn.edu/biology/wkshp_abstracts/park1.html" rel="nofollow">
    Interaural Intensity Difference Processing in Auditory Midbrain Neurons: Effects of a Transient Early Inhibitory Input
   </a>
  </li>
  <li>
   <a class="external text" href="http://highered.mcgraw-hill.com/sites/0070579431/student_view0/chapter11/glossary.html" rel="nofollow">
    Online learning center - Hearing and Listening
   </a>
  </li>
  <li>
   <a class="external text" href="http://hearcom.eu" rel="nofollow">
    HearCom:Hearing in the Communication Society, an EU research project
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.archive.org/web/20080602152533/http://cmr.mech.unsw.edu.au/research_areas?q=node%2F23" rel="nofollow">
    Research on "Non-line-of-sight (NLOS) Localisation for Indoor Environments" by CMR at UNSW
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.archive.org/web/20010306145145/http://www.aip.org/pt/nov99/locsound.html" rel="nofollow">
    An introduction to sound localization
   </a>
  </li>
  <li>
   <a class="external text" href="http://www.holophony.net/Sound%20and%20Room.htm" rel="nofollow">
    Sound and Room
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.archive.org/web/20100415001954/http://www.lmsintl.com/acoustic-holography" rel="nofollow">
    An introduction to acoustic holography
   </a>
  </li>
  <li>
   <a class="external text" href="https://web.archive.org/web/20100415001951/http://www.lmsintl.com/acoustic-beamforming" rel="nofollow">
    An introduction to acoustic beamforming
   </a>
  </li>
  <li>
   Link to reference 8:
   <a class="external free" href="https://kns.cnki.net/kcms2/article/abstract?v=C1uazonQNNh31hpdlsyEyXcqR2uafvd3NO5N-rwCbIvv4k-h-lQ2euw2Ja7xMXcwObpETefJWcYFa1zXJqT8ezXCQyp8UxeCVFCuTs07Lhqt4Qc6zy4aOw==&amp;uniplatform=NZKPT" rel="nofollow">
    https://kns.cnki.net/kcms2/article/abstract?v=C1uazonQNNh31hpdlsyEyXcqR2uafvd3NO5N-rwCbIvv4k-h-lQ2euw2Ja7xMXcwObpETefJWcYFa1zXJqT8ezXCQyp8UxeCVFCuTs07Lhqt4Qc6zy4aOw==&amp;uniplatform=NZKPT
   </a>
  </li>
 </ul>
 <div class="navbox-styles">
  <style data-mw-deduplicate="TemplateStyles:r1129693374">
   .mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}
  </style>
  <style data-mw-deduplicate="TemplateStyles:r1236075235">
   .mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}
  </style>
 </div>
 <div aria-labelledby="Neuroethology" class="navbox" role="navigation" style="padding:3px">
  <table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit">
   <tbody>
    <tr>
     <th class="navbox-title" colspan="2" scope="col">
      <link href="mw-data:TemplateStyles:r1129693374" rel="mw-deduplicated-inline-style"/>
      <style data-mw-deduplicate="TemplateStyles:r1236085633">
       .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}
      </style>
      <div class="navbar plainlinks hlist navbar-mini">
       <ul>
        <li class="nv-view">
         <a href="/wiki/Template:Neuroethology" title="Template:Neuroethology">
          <abbr title="View this template">
           v
          </abbr>
         </a>
        </li>
        <li class="nv-talk">
         <a href="/wiki/Template_talk:Neuroethology" title="Template talk:Neuroethology">
          <abbr title="Discuss this template">
           t
          </abbr>
         </a>
        </li>
        <li class="nv-edit">
         <a href="/wiki/Special:EditPage/Template:Neuroethology" title="Special:EditPage/Template:Neuroethology">
          <abbr title="Edit this template">
           e
          </abbr>
         </a>
        </li>
       </ul>
      </div>
      <div id="Neuroethology" style="font-size:114%;margin:0 4em">
       <a href="/wiki/Neuroethology" title="Neuroethology">
        Neuroethology
       </a>
      </div>
     </th>
    </tr>
    <tr>
     <th class="navbox-group" scope="row" style="width:1%">
      Concepts
     </th>
     <td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0">
      <div style="padding:0 0.25em">
       <ul>
        <li>
         <a href="/wiki/Feed_forward_(control)" title="Feed forward (control)">
          Feedforward
         </a>
        </li>
        <li>
         <a href="/wiki/Coincidence_detection_in_neurobiology" title="Coincidence detection in neurobiology">
          Coincidence detector
         </a>
        </li>
        <li>
         <i>
          <a href="/wiki/Umwelt" title="Umwelt">
           Umwelt
          </a>
         </i>
        </li>
        <li>
         <a href="/wiki/Instinct" title="Instinct">
          Instinct
         </a>
        </li>
        <li>
         <a href="/wiki/Feature_detection_(nervous_system)" title="Feature detection (nervous system)">
          Feature detection
         </a>
        </li>
        <li>
         <a href="/wiki/Central_pattern_generator" title="Central pattern generator">
          Central pattern generator (CPG)
         </a>
        </li>
        <li>
         <a href="/wiki/NMDA_receptor" title="NMDA receptor">
          NMDA receptor
         </a>
        </li>
        <li>
         <a href="/wiki/Lateral_inhibition" title="Lateral inhibition">
          Lateral inhibition
         </a>
        </li>
        <li>
         <a href="/wiki/Fixed_action_pattern" title="Fixed action pattern">
          Fixed action pattern
         </a>
        </li>
        <li>
         <a class="mw-redirect" href="/wiki/Krogh%27s_Principle" title="Krogh's Principle">
          Krogh's Principle
         </a>
        </li>
        <li>
         <a href="/wiki/Hebbian_theory" title="Hebbian theory">
          Hebbian theory
         </a>
        </li>
        <li>
         <a href="/wiki/Anti-Hebbian_learning" title="Anti-Hebbian learning">
          Anti-Hebbian learning
         </a>
        </li>
        <li>
         <a class="mw-selflink selflink">
          Sound localization
         </a>
        </li>
        <li>
         <a href="/wiki/Ultrasound_avoidance" title="Ultrasound avoidance">
          Ultrasound avoidance
         </a>
         in insects
        </li>
       </ul>
      </div>
     </td>
    </tr>
    <tr>
     <th class="navbox-group" scope="row" style="width:1%">
      People
     </th>
     <td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0">
      <div style="padding:0 0.25em">
       <ul>
        <li>
         <a href="/wiki/Theodore_Holmes_Bullock" title="Theodore Holmes Bullock">
          Theodore Holmes Bullock
         </a>
        </li>
        <li>
         <a href="/wiki/Walter_Heiligenberg" title="Walter Heiligenberg">
          Walter Heiligenberg
         </a>
        </li>
        <li>
         <a href="/wiki/Nikolaas_Tinbergen" title="Nikolaas Tinbergen">
          Niko Tinbergen
         </a>
        </li>
        <li>
         <a href="/wiki/Konrad_Lorenz" title="Konrad Lorenz">
          Konrad Lorenz
         </a>
        </li>
        <li>
         <a href="/wiki/Donald_Griffin" title="Donald Griffin">
          Donald Griffin
         </a>
        </li>
        <li>
         <a href="/wiki/Donald_Kennedy" title="Donald Kennedy">
          Donald Kennedy
         </a>
        </li>
        <li>
         <a href="/wiki/Karl_von_Frisch" title="Karl von Frisch">
          Karl von Frisch
         </a>
        </li>
        <li>
         <a href="/wiki/Erich_von_Holst" title="Erich von Holst">
          Erich von Holst
         </a>
        </li>
        <li>
         <a href="/wiki/J%C3%B6rg-Peter_Ewert" title="Jörg-Peter Ewert">
          Jörg-Peter Ewert
         </a>
        </li>
        <li>
         <a href="/wiki/Franz_Huber" title="Franz Huber">
          Franz Huber
         </a>
        </li>
        <li>
         <a href="/wiki/Bernhard_Hassenstein" title="Bernhard Hassenstein">
          Bernhard Hassenstein
         </a>
        </li>
        <li>
         <a href="/wiki/Werner_E._Reichardt" title="Werner E. Reichardt">
          Werner E. Reichardt
         </a>
        </li>
        <li>
         <a href="/wiki/Eric_Knudsen" title="Eric Knudsen">
          Eric Knudsen
         </a>
        </li>
        <li>
         <a href="/wiki/Eric_Kandel" title="Eric Kandel">
          Eric Kandel
         </a>
        </li>
        <li>
         <a href="/wiki/Nobuo_Suga" title="Nobuo Suga">
          Nobuo Suga
         </a>
        </li>
        <li>
         <a href="/wiki/Masakazu_Konishi" title="Masakazu Konishi">
          Masakazu Konishi
         </a>
        </li>
        <li>
         <a href="/wiki/Fernando_Nottebohm" title="Fernando Nottebohm">
          Fernando Nottebohm
         </a>
        </li>
       </ul>
      </div>
     </td>
    </tr>
    <tr>
     <th class="navbox-group" scope="row" style="width:1%">
      Methods
     </th>
     <td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0">
      <div style="padding:0 0.25em">
       <ul>
        <li>
         <a href="/wiki/Patch_clamp" title="Patch clamp">
          Patch clamp
         </a>
        </li>
        <li>
         <a href="/wiki/Slice_preparation" title="Slice preparation">
          Slice preparation
         </a>
        </li>
       </ul>
      </div>
     </td>
    </tr>
    <tr>
     <th class="navbox-group" scope="row" style="width:1%">
      Systems
     </th>
     <td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0">
      <div style="padding:0 0.25em">
       <ul>
        <li>
         <a href="/wiki/Animal_echolocation" title="Animal echolocation">
          Animal echolocation
         </a>
        </li>
        <li>
         <a href="/wiki/Waggle_dance" title="Waggle dance">
          Waggle dance
         </a>
        </li>
        <li>
         <a href="/wiki/Jamming_avoidance_response" title="Jamming avoidance response">
          Jamming avoidance response
         </a>
        </li>
        <li>
         <a href="/wiki/Vision_in_toads" title="Vision in toads">
          Vision in toads
         </a>
        </li>
        <li>
         <a href="/wiki/Frog_hearing_and_communication" title="Frog hearing and communication">
          Frog hearing and communication
         </a>
        </li>
        <li>
         <a href="/wiki/Infrared_sensing_in_snakes" title="Infrared sensing in snakes">
          Infrared sensing in snakes
         </a>
        </li>
        <li>
         <a href="/wiki/Caridoid_escape_reaction" title="Caridoid escape reaction">
          Caridoid escape reaction
         </a>
        </li>
        <li>
         <a href="/wiki/Vocal_learning" title="Vocal learning">
          Vocal learning
         </a>
        </li>
        <li>
         <a class="mw-redirect" href="/wiki/Surface_wave_detection" title="Surface wave detection">
          Surface wave detection
         </a>
        </li>
        <li>
         <a class="mw-redirect" href="/wiki/Electroreception" title="Electroreception">
          Electroreception
         </a>
        </li>
        <li>
         <a class="mw-redirect" href="/wiki/Mechanoreception" title="Mechanoreception">
          Mechanoreception
         </a>
         <ul>
          <li>
           <a href="/wiki/Lateral_line" title="Lateral line">
            Lateral line
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </div>
     </td>
    </tr>
    <tr>
     <td class="navbox-abovebelow hlist" colspan="2">
      <div>
       <ul>
        <li>
         <span class="noviewer" typeof="mw:File">
          <span title="Category">
           <img alt="" class="mw-file-element" data-file-height="185" data-file-width="180" decoding="async" height="16" src="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x" width="16"/>
          </span>
         </span>
         <b>
          <a href="/wiki/Category:Neuroethology" title="Category:Neuroethology">
           Category
          </a>
         </b>
        </li>
        <li>
         <span class="noviewer" typeof="mw:File">
          <span title="Commons page">
           <img alt="" class="mw-file-element" data-file-height="1376" data-file-width="1024" decoding="async" height="16" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" width="12"/>
          </span>
         </span>
         <b>
          <a class="extiw" href="https://commons.wikimedia.org/wiki/Category:Neuroethology" title="commons:Category:Neuroethology">
           Commons
          </a>
         </b>
        </li>
       </ul>
      </div>
     </td>
    </tr>
   </tbody>
  </table>
 </div>
 <!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐8b89949cb‐4mfjw
Cached time: 20240723173509
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.739 seconds
Real time usage: 0.992 seconds
Preprocessor visited node count: 2886/1000000
Post‐expand include size: 71941/2097152 bytes
Template argument size: 3453/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 10/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 103935/5000000 bytes
Lua time usage: 0.444/10.000 seconds
Lua memory usage: 6517617/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
 <!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  778.664      1 -total
 37.71%  293.607      1 Template:Reflist
 25.24%  196.524     14 Template:Cite_journal
 15.67%  122.053      1 Template:Neuroethology
 15.37%  119.719      1 Template:Navbox
 12.30%   95.740      1 Template:Short_description
  9.95%   77.498      1 Template:Lead_too_short
  9.05%   70.506      1 Template:Ambox
  8.51%   66.249      5 Template:Fix
  6.41%   49.906      2 Template:Pagetype
-->
 <!-- Saved in parser cache with key enwiki:pcache:idhash:1021754-0!canonical and timestamp 20240723173509 and revision id 1229336831. Rendering was triggered because: page-view
 -->
</div>
