<div class="mw-content-ltr mw-parser-output" dir="ltr" lang="en">
 <style data-mw-deduplicate="TemplateStyles:r1236091366">
  .mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}
 </style>
 <table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation">
  <tbody>
   <tr>
    <td class="mbox-image">
     <div class="mbox-image-div">
      <span typeof="mw:File">
       <a class="mw-file-description" href="/wiki/File:Question_book-new.svg">
        <img alt="" class="mw-file-element" data-file-height="399" data-file-width="512" decoding="async" height="39" src="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x" width="50"/>
       </a>
      </span>
     </div>
    </td>
    <td class="mbox-text">
     <div class="mbox-text-span">
      This article
      <b>
       needs additional citations for
       <a href="/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">
        verification
       </a>
      </b>
      .
      <span class="hide-when-compact">
       Please help
       <a href="/wiki/Special:EditPage/Auditory_scene_analysis" title="Special:EditPage/Auditory scene analysis">
        improve this article
       </a>
       by
       <a href="/wiki/Help:Referencing_for_beginners" title="Help:Referencing for beginners">
        adding citations to reliable sources
       </a>
       . Unsourced material may be challenged and removed.
       <br/>
       <small>
        <span class="plainlinks">
         <i>
          Find sources:
         </i>
         <a class="external text" href="https://www.google.com/search?as_eq=wikipedia&amp;q=%22Auditory+scene+analysis%22" rel="nofollow">
          "Auditory scene analysis"
         </a>
         –
         <a class="external text" href="https://www.google.com/search?tbm=nws&amp;q=%22Auditory+scene+analysis%22+-wikipedia&amp;tbs=ar:1" rel="nofollow">
          news
         </a>
         <b>
          ·
         </b>
         <a class="external text" href="https://www.google.com/search?&amp;q=%22Auditory+scene+analysis%22&amp;tbs=bkt:s&amp;tbm=bks" rel="nofollow">
          newspapers
         </a>
         <b>
          ·
         </b>
         <a class="external text" href="https://www.google.com/search?tbs=bks:1&amp;q=%22Auditory+scene+analysis%22+-wikipedia" rel="nofollow">
          books
         </a>
         <b>
          ·
         </b>
         <a class="external text" href="https://scholar.google.com/scholar?q=%22Auditory+scene+analysis%22" rel="nofollow">
          scholar
         </a>
         <b>
          ·
         </b>
         <a class="external text" href="https://www.jstor.org/action/doBasicSearch?Query=%22Auditory+scene+analysis%22&amp;acc=on&amp;wc=on" rel="nofollow">
          JSTOR
         </a>
        </span>
       </small>
      </span>
      <span class="date-container">
       <i>
        (
        <span class="date">
         May 2008
        </span>
        )
       </i>
      </span>
      <span class="hide-when-compact">
       <i>
        (
        <small>
         <a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">
          Learn how and when to remove this message
         </a>
        </small>
        )
       </i>
      </span>
     </div>
    </td>
   </tr>
  </tbody>
 </table>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:Albert_S._Bregman.JPG">
   <img class="mw-file-element" data-file-height="703" data-file-width="559" decoding="async" height="277" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Albert_S._Bregman.JPG/220px-Albert_S._Bregman.JPG" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Albert_S._Bregman.JPG/330px-Albert_S._Bregman.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Albert_S._Bregman.JPG/440px-Albert_S._Bregman.JPG 2x" width="220"/>
  </a>
  <figcaption>
   <a href="/wiki/Albert_Bregman" title="Albert Bregman">
    Albert Bregman
   </a>
   , 2011
  </figcaption>
 </figure>
 <p>
  In
  <a href="/wiki/Perception" title="Perception">
   perception
  </a>
  and
  <a href="/wiki/Psychophysics" title="Psychophysics">
   psychophysics
  </a>
  ,
  <b>
   auditory scene analysis
  </b>
  (
  <b>
   ASA
  </b>
  ) is a proposed model for the basis of auditory perception. This is understood as the process by which the human auditory system organizes sound into perceptually meaningful elements. The term was coined by psychologist
  <a href="/wiki/Albert_Bregman" title="Albert Bregman">
   Albert Bregman
  </a>
  .
  <sup class="reference" id="cite_ref-bregman90_1-0">
   <a href="#cite_note-bregman90-1">
    [1]
   </a>
  </sup>
  The related concept in
  <a href="/wiki/Machine_perception" title="Machine perception">
   machine perception
  </a>
  is
  <a href="/wiki/Computational_auditory_scene_analysis" title="Computational auditory scene analysis">
   computational auditory scene analysis
  </a>
  (CASA), which is closely related to
  <a href="/wiki/Signal_separation" title="Signal separation">
   source separation
  </a>
  and
  <a class="mw-redirect" href="/wiki/Blind_signal_separation" title="Blind signal separation">
   blind signal separation
  </a>
  .
 </p>
 <p>
  The three key aspects of Bregman's ASA model are: segmentation, integration, and segregation.
 </p>
 <meta property="mw:PageProp/toc"/>
 <div class="mw-heading mw-heading2">
  <h2 id="Background">
   Background
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Auditory_scene_analysis&amp;action=edit&amp;section=1" title="Edit section: Background">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Sound reaches the ear and the eardrum vibrates as a whole. This signal has to be analyzed (in some way). Bregman's ASA model proposes that sounds will either be heard as "integrated" (heard as a whole – much like harmony in music), or "segregated" into individual components (which leads to counterpoint).
  <sup class="reference" id="cite_ref-2">
   <a href="#cite_note-2">
    [2]
   </a>
  </sup>
  For example, a bell can be heard as a 'single' sound (integrated), or some people are able to hear the individual components – they are able to segregate the sound. This can be done with chords where it can be heard as a 'color', or as the individual notes. Natural
  <a href="/wiki/Sound" title="Sound">
   sounds
  </a>
  , such as the
  <a href="/wiki/Speech" title="Speech">
   human voice
  </a>
  ,
  <a href="/wiki/Musical_tone" title="Musical tone">
   musical instruments
  </a>
  , or cars passing in the street, are made up of many frequencies, which contribute to the perceived quality (like timbre) of the sounds. When two or more natural sounds occur at once, all the components of the simultaneously active sounds are received at the same time, or overlapped in time, by the ears of listeners. This presents their auditory systems with a problem: which parts of the sound should be grouped together and treated as parts of the same source or object? Grouping them incorrectly can cause the listener to hear non-existent sounds built from the wrong combinations of the original components.
 </p>
 <p>
  In many circumstances the segregated elements can be linked together in time, producing an auditory stream. This ability of auditory streaming can be demonstrated by the so-called
  <a href="/wiki/Cocktail_party_effect" title="Cocktail party effect">
   cocktail party effect
  </a>
  . Up to a point, with a number of voices speaking at the same time or with background sounds, one is able to follow a particular voice even though other voices and background sounds are present.
  <sup class="reference" id="cite_ref-3">
   <a href="#cite_note-3">
    [3]
   </a>
  </sup>
  In this example, the ear is segregating this voice from other sounds (which are integrated), and the mind "streams" these segregated sounds into an auditory stream. This is a skill which is highly developed by musicians, notably conductors who are able to listen to one, two, three or more instruments at the same time (segregating them), and following each as an independent line through auditory streaming
  <sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">
   [
   <i>
    <a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">
     <span title="This claim needs references to reliable sources. (March 2018)">
      citation needed
     </span>
    </a>
   </i>
   ]
  </sup>
  .
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Grouping_and_streams">
   Grouping and streams
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Auditory_scene_analysis&amp;action=edit&amp;section=2" title="Edit section: Grouping and streams">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  A number of grouping principles appear to underlie ASA, many of which are related to principles of perceptual organization discovered by the school of
  <a href="/wiki/Gestalt_psychology" title="Gestalt psychology">
   Gestalt psychology
  </a>
  . These can be broadly categorized into
  <b>
   sequential grouping
  </b>
  mechanisms (those that operate across time) and
  <b>
   simultaneous grouping
  </b>
  mechanisms (those that operate across frequency):
 </p>
 <ul>
  <li>
   Errors in simultaneous grouping can lead to the blending of sounds that should be heard as separate, the blended sounds having different perceived qualities (such as pitch or timbre) to any of the sounds actually received. For instance two vowels presented simultaneously may not be identifiable if they are segregated.
   <sup class="reference" id="cite_ref-4">
    <a href="#cite_note-4">
     [4]
    </a>
   </sup>
  </li>
  <li>
   Errors in sequential grouping can lead, for example, to hearing a word created out of syllables originating from two different voices.
   <sup class="reference" id="cite_ref-5">
    <a href="#cite_note-5">
     [5]
    </a>
   </sup>
   <sup class="reference" id="cite_ref-6">
    <a href="#cite_note-6">
     [6]
    </a>
   </sup>
  </li>
 </ul>
 <p>
  Segregation can be based primarily on perceptual cues or rely on the recognition of learned patterns ("schema-based").
 </p>
 <p>
  The job of ASA is to group incoming sensory information to form an accurate mental representation of the individual sounds. When sounds are grouped by the auditory system into a perceived sequence, distinct from other co-occurring sequences, each of these perceived sequences is called an "auditory stream". In the real world, if the ASA is successful, a stream corresponds to a distinct environmental sound source producing a pattern that persists over time, such as a person talking, a piano playing, or a dog barking. However, in the lab, by manipulating the acoustic parameters of the sounds, it is possible to induce the perception of one or more auditory streams.
 </p>
 <figure class="mw-default-size" typeof="mw:File/Thumb">
  <a class="mw-file-description" href="/wiki/File:Streaming_in_Auditory_Scene_Analysis.gif">
   <img class="mw-file-element" data-file-height="540" data-file-width="960" decoding="async" height="124" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Streaming_in_Auditory_Scene_Analysis.gif/220px-Streaming_in_Auditory_Scene_Analysis.gif" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Streaming_in_Auditory_Scene_Analysis.gif/330px-Streaming_in_Auditory_Scene_Analysis.gif 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Streaming_in_Auditory_Scene_Analysis.gif/440px-Streaming_in_Auditory_Scene_Analysis.gif 2x" width="220"/>
  </a>
  <figcaption>
   Streaming in Auditory Scene Analysis
  </figcaption>
 </figure>
 <p>
  One example of this is the phenomenon of
  <a href="/wiki/Melodic_fission" title="Melodic fission">
   streaming
  </a>
  , also called "stream segregation."
  <sup class="reference" id="cite_ref-7">
   <a href="#cite_note-7">
    [7]
   </a>
  </sup>
  If two sounds, A and B, are rapidly alternated in time, after a few seconds the perception may seem to "split" so that the listener hears two rather than one stream of sound, each stream corresponding to the repetitions of one of the two sounds, for example, A-A-A-A-, etc. accompanied by B-B-B-B-, etc. The tendency towards segregation into separate streams is favored  by differences in the acoustical properties of sounds A and B. Among the differences classically shown to promote segregation are those of frequency (for
  <a href="/wiki/Pure_tone" title="Pure tone">
   pure tones
  </a>
  ), fundamental frequency (for
  <a href="/wiki/Musical_tone" title="Musical tone">
   complex tones
  </a>
  ), frequency composition, source location. But it has been suggested that about any systematic perceptual difference between two sequences can elicit streaming,
  <sup class="reference" id="cite_ref-8">
   <a href="#cite_note-8">
    [8]
   </a>
  </sup>
  provided the speed of the sequence is sufficient.
 </p>
 <p>
  An interactive web page illustrating this streaming and the importance of frequency separation and speed
  <a class="external text" href="http://auditoryneuroscience.com/?q=topics/streaming-galloping-rhythm-paradigm" rel="nofollow">
   can be found here.
  </a>
 </p>
 <p>
  <a href="/wiki/Andranik_Tangian" title="Andranik Tangian">
   Andranik Tangian
  </a>
  argues that the grouping phenomenon is observed not only in dynamics but in statics as well. For instance, the sensation of a chord is the effect of acoustical data representation rather than physical causality (indeed, a single physical body, like a loudspeaker membrane, can produce an effect of several tones, and several physical bodies, like organ pipes tuned as a chord, can produce an effect of a single tone). From the viewpoint of
  <a href="/wiki/Musical_acoustics" title="Musical acoustics">
   musical acoustics
  </a>
  , a chord is a special kind of sound whose
  <a href="/wiki/Spectrum" title="Spectrum">
   spectrum
  </a>
  — the set of partial tones (sinusoidal oscillations) — can be regarded as generated by displacements of a single tone spectrum along the frequency axis. In other words, the chord's interval structure is an acoustical contour drawn by a tone (in dynamics, polyphonic voices are trajectories of tone spectra). This is justified by the information theory. If the generative tone is harmonic (= has a pitch salience) then such a representation is proved to be unique and requires the least amount of memory, i.e. is the least complex in the sense of
  <a class="mw-redirect" href="/wiki/Kolmogorov" title="Kolmogorov">
   Kolmogorov
  </a>
  . Since it is simpler all other representations, including the one where the chord is regarded as a single complex sound, the chord is perceived as a compound. If the generative tone is inharmonic, like a bell-like sound, the interval structure is still recognizable as displacements of a tone spectrum, whose pitch can be even undetectable. This optimal representation-based definition of a chord explains, among other things, the predominance of interval hearing over the absolute pitch hearing.
  <sup class="reference" id="cite_ref-Tanguiane1993_9-0">
   <a href="#cite_note-Tanguiane1993-9">
    [9]
   </a>
  </sup>
  <sup class="reference" id="cite_ref-Tangian1994_10-0">
   <a href="#cite_note-Tangian1994-10">
    [10]
   </a>
  </sup>
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="Experimental_basis">
   Experimental basis
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Auditory_scene_analysis&amp;action=edit&amp;section=3" title="Edit section: Experimental basis">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <p>
  Many experiments have studied the segregation of more complex patterns of sound, such as a sequence of high notes of different pitches, interleaved with low ones.  In such sequences, the segregation of co-occurring sounds into distinct streams has a profound effect on the way they are heard. Perception of a melody is formed more easily if all its notes fall in the same auditory stream.  We tend to hear the rhythms among notes that are in the same stream, excluding those that are in other streams.  Judgments of timing are more precise between notes in the same stream than between notes in separate streams.  Even perceived spatial location and perceived loudness can be affected by sequential grouping. While the initial research on this topic was done on human adults, recent studies have shown that some ASA capabilities are present in newborn infants, showing that they are built-in, rather than learned through experience.  Other research has shown that non-human animals also display ASA.  Currently, scientists are studying the activity of neurons in the auditory regions of the cerebral cortex to discover the mechanisms underlying ASA.
 </p>
 <div class="mw-heading mw-heading2">
  <h2 id="See_also">
   See also
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Auditory_scene_analysis&amp;action=edit&amp;section=4" title="Edit section: See also">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <ul>
  <li>
   <a href="/wiki/Illusory_discontinuity" title="Illusory discontinuity">
    Illusory discontinuity
   </a>
  </li>
  <li>
   <a href="/wiki/Phonemic_restoration_effect" title="Phonemic restoration effect">
    Phonemic restoration effect
   </a>
  </li>
  <li>
   <a href="/wiki/Theory_of_indispensable_attributes" title="Theory of indispensable attributes">
    Theory of indispensable attributes
   </a>
  </li>
 </ul>
 <div class="mw-heading mw-heading2">
  <h2 id="References">
   References
  </h2>
  <span class="mw-editsection">
   <span class="mw-editsection-bracket">
    [
   </span>
   <a href="/w/index.php?title=Auditory_scene_analysis&amp;action=edit&amp;section=5" title="Edit section: References">
    <span>
     edit
    </span>
   </a>
   <span class="mw-editsection-bracket">
    ]
   </span>
  </span>
 </div>
 <style data-mw-deduplicate="TemplateStyles:r1217336898">
  .mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}
 </style>
 <div class="reflist">
  <div class="mw-references-wrap">
   <ol class="references">
    <li id="cite_note-bregman90-1">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-bregman90_1-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <style data-mw-deduplicate="TemplateStyles:r1215172403">
       .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a{background-size:contain}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a{background-size:contain}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a{background-size:contain}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#2C882D;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911F}html.skin-theme-clientpref-night .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-night .mw-parser-output .cs1-hidden-error{color:#f8a397}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-os .mw-parser-output .cs1-hidden-error{color:#f8a397}html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911F}}
      </style>
      <cite class="citation book cs1" id="CITEREFBregman,_A._S.1990">
       Bregman, A. S. (1990).
       <i>
        Auditory scene analysis: The Perceptual Organization of Sound
       </i>
       . Cambridge, MA: MIT Press.
       <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">
        ISBN
       </a>
       <a href="/wiki/Special:BookSources/9780262022972" title="Special:BookSources/9780262022972">
        <bdi>
         9780262022972
        </bdi>
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Auditory+scene+analysis%3A+The+Perceptual+Organization+of+Sound&amp;rft.place=Cambridge%2C+MA&amp;rft.pub=MIT+Press&amp;rft.date=1990&amp;rft.isbn=9780262022972&amp;rft.au=Bregman%2C+A.+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-2">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-2">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFWright1987">
       Wright, James and Albert S. Bregman (1987). "Auditory Stream Segregation and the Control of Dissonance in Polyphonic Music".
       <i>
        Contemporary Music Review
       </i>
       .
       <b>
        2
       </b>
       (1): 63-92.
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Contemporary+Music+Review&amp;rft.atitle=Auditory+Stream+Segregation+and+the+Control+of+Dissonance+in+Polyphonic+Music.&amp;rft.volume=2&amp;rft.issue=1&amp;rft.pages=63-92&amp;rft.date=1987&amp;rft.aulast=Wright&amp;rft.aufirst=James+and+Albert+S.+Bregman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-3">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-3">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFMiller1947">
       Miller, G. A. (1947). "The masking of speech".
       <i>
        Psychological Bulletin
       </i>
       .
       <b>
        44
       </b>
       (2): 105–129.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1037%2Fh0055960" rel="nofollow">
        10.1037/h0055960
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20288932" rel="nofollow">
        20288932
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Bulletin&amp;rft.atitle=The+masking+of+speech.&amp;rft.volume=44&amp;rft.issue=2&amp;rft.pages=105-129&amp;rft.date=1947&amp;rft_id=info%3Adoi%2F10.1037%2Fh0055960&amp;rft_id=info%3Apmid%2F20288932&amp;rft.aulast=Miller&amp;rft.aufirst=G.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-4">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-4">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFAssmannSummerfield1990">
       Assmann, P. F.; Summerfield, Q. (August 1990). "Modeling the perception of concurrent vowels: Vowels with different fundamental frequencies".
       <i>
        The Journal of the Acoustical Society of America
       </i>
       .
       <b>
        88
       </b>
       (2): 680–697.
       <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">
        Bibcode
       </a>
       :
       <a class="external text" href="https://ui.adsabs.harvard.edu/abs/1990ASAJ...88..680A" rel="nofollow">
        1990ASAJ...88..680A
       </a>
       .
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1121%2F1.399772" rel="nofollow">
        10.1121/1.399772
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/2212292" rel="nofollow">
        2212292
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+the+Acoustical+Society+of+America&amp;rft.atitle=Modeling+the+perception+of+concurrent+vowels%3A+Vowels+with+different+fundamental+frequencies&amp;rft.volume=88&amp;rft.issue=2&amp;rft.pages=680-697&amp;rft.date=1990-08&amp;rft_id=info%3Apmid%2F2212292&amp;rft_id=info%3Adoi%2F10.1121%2F1.399772&amp;rft_id=info%3Abibcode%2F1990ASAJ...88..680A&amp;rft.aulast=Assmann&amp;rft.aufirst=P.+F.&amp;rft.au=Summerfield%2C+Q.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-5">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-5">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFGaudrainGrimaultHealyBéra2007">
       Gaudrain, E.; Grimault, N.; Healy, E. W.; Béra, J.-C. (2007).
       <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2128787" rel="nofollow">
        "Effect of spectral smearing on the perceptual segregation of vowel sequences"
       </a>
       .
       <i>
        Hearing Research
       </i>
       .
       <b>
        231
       </b>
       (1–2): 32–41.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1016%2Fj.heares.2007.05.001" rel="nofollow">
        10.1016/j.heares.2007.05.001
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">
        PMC
       </a>
       <span class="id-lock-free" title="Freely accessible">
        <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2128787" rel="nofollow">
         2128787
        </a>
       </span>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/17597319" rel="nofollow">
        17597319
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Hearing+Research&amp;rft.atitle=Effect+of+spectral+smearing+on+the+perceptual+segregation+of+vowel+sequences&amp;rft.volume=231&amp;rft.issue=1%E2%80%932&amp;rft.pages=32-41&amp;rft.date=2007&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2128787%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F17597319&amp;rft_id=info%3Adoi%2F10.1016%2Fj.heares.2007.05.001&amp;rft.aulast=Gaudrain&amp;rft.aufirst=E.&amp;rft.au=Grimault%2C+N.&amp;rft.au=Healy%2C+E.+W.&amp;rft.au=B%C3%A9ra%2C+J.-C.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2128787&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-6">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-6">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFBilligDavisDeeksMonstrey2013">
       Billig, A. J.; Davis, M. H.; Deeks, J. M.; Monstrey, J.; Carlyon, R. P. (2013).
       <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3748342" rel="nofollow">
        "Lexical Influences on Auditory Streaming"
       </a>
       .
       <i>
        Current Biology
       </i>
       .
       <b>
        23
       </b>
       (16): 1585–1589.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1016%2Fj.cub.2013.06.042" rel="nofollow">
        10.1016/j.cub.2013.06.042
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">
        PMC
       </a>
       <span class="id-lock-free" title="Freely accessible">
        <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3748342" rel="nofollow">
         3748342
        </a>
       </span>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/23891107" rel="nofollow">
        23891107
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Current+Biology&amp;rft.atitle=Lexical+Influences+on+Auditory+Streaming&amp;rft.volume=23&amp;rft.issue=16&amp;rft.pages=1585-1589&amp;rft.date=2013&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3748342%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F23891107&amp;rft_id=info%3Adoi%2F10.1016%2Fj.cub.2013.06.042&amp;rft.aulast=Billig&amp;rft.aufirst=A.+J.&amp;rft.au=Davis%2C+M.+H.&amp;rft.au=Deeks%2C+J.+M.&amp;rft.au=Monstrey%2C+J.&amp;rft.au=Carlyon%2C+R.+P.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3748342&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-7">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-7">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation thesis cs1" id="CITEREFvan_Noorden1975">
       van Noorden, L. P. A. S. (1975).
       <a class="external text" href="http://alexandria.tue.nl/extra1/PRF2A/7707058.pdf" rel="nofollow">
        <i>
         Temporal coherence in the perception of tones sequences
        </i>
       </a>
       <span class="cs1-format">
        (PDF)
       </span>
       (PhD). The Netherlands: Eindhoven University of Technology
       <span class="reference-accessdate">
        . Retrieved
        <span class="nowrap">
         10 March
        </span>
        2018
       </span>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Temporal+coherence+in+the+perception+of+tones+sequences&amp;rft.inst=Eindhoven+University+of+Technology&amp;rft.date=1975&amp;rft.aulast=van+Noorden&amp;rft.aufirst=L.+P.+A.+S.&amp;rft_id=http%3A%2F%2Falexandria.tue.nl%2Fextra1%2FPRF2A%2F7707058.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-8">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-8">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFMooreGockel2012">
       Moore, B. C. J.; Gockel, H. E. (2012).
       <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3282308" rel="nofollow">
        "Properties of auditory stream formation"
       </a>
       .
       <i>
        Philosophical Transactions of the Royal Society B: Biological Sciences
       </i>
       .
       <b>
        367
       </b>
       (1591): 919–931.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.1098%2Frstb.2011.0355" rel="nofollow">
        10.1098/rstb.2011.0355
       </a>
       .
       <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">
        PMC
       </a>
       <span class="id-lock-free" title="Freely accessible">
        <a class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3282308" rel="nofollow">
         3282308
        </a>
       </span>
       .
       <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">
        PMID
       </a>
       <a class="external text" href="https://pubmed.ncbi.nlm.nih.gov/22371614" rel="nofollow">
        22371614
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B%3A+Biological+Sciences&amp;rft.atitle=Properties+of+auditory+stream+formation&amp;rft.volume=367&amp;rft.issue=1591&amp;rft.pages=919-931&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3282308%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F22371614&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2011.0355&amp;rft.aulast=Moore&amp;rft.aufirst=B.+C.+J.&amp;rft.au=Gockel%2C+H.+E.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3282308&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-Tanguiane1993-9">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-Tanguiane1993_9-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation book cs1" id="CITEREFTanguiane_(Tangian)1993">
       Tanguiane (Tangian), Andranick (1993).
       <i>
        Artificial Perception and Music Recognition
       </i>
       . Lecture Notes in Artificial Intelligence. Vol. 746. Berlin-Heidelberg: Springer.
       <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">
        ISBN
       </a>
       <a href="/wiki/Special:BookSources/978-3-540-57394-4" title="Special:BookSources/978-3-540-57394-4">
        <bdi>
         978-3-540-57394-4
        </bdi>
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Perception+and+Music+Recognition&amp;rft.place=Berlin-Heidelberg&amp;rft.series=Lecture+Notes+in+Artificial+Intelligence&amp;rft.pub=Springer&amp;rft.date=1993&amp;rft.isbn=978-3-540-57394-4&amp;rft.aulast=Tanguiane+%28Tangian%29&amp;rft.aufirst=Andranick&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
    <li id="cite_note-Tangian1994-10">
     <span class="mw-cite-backlink">
      <b>
       <a href="#cite_ref-Tangian1994_10-0">
        ^
       </a>
      </b>
     </span>
     <span class="reference-text">
      <link href="mw-data:TemplateStyles:r1215172403" rel="mw-deduplicated-inline-style"/>
      <cite class="citation journal cs1" id="CITEREFTanguiane_(Tanguiane)1994">
       Tanguiane (Tanguiane), Andranick (1994). "A principle of correlativity of perception and its application to music recognition".
       <i>
        Music Perception
       </i>
       .
       <b>
        11
       </b>
       (4): 465–502.
       <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">
        doi
       </a>
       :
       <a class="external text" href="https://doi.org/10.2307%2F40285634" rel="nofollow">
        10.2307/40285634
       </a>
       .
      </cite>
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Music+Perception&amp;rft.atitle=A+principle+of+correlativity+of+perception+and+its+application+to+music+recognition&amp;rft.volume=11&amp;rft.issue=4&amp;rft.pages=465-502&amp;rft.date=1994&amp;rft_id=info%3Adoi%2F10.2307%2F40285634&amp;rft.aulast=Tanguiane+%28Tanguiane%29&amp;rft.aufirst=Andranick&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAuditory+scene+analysis">
      </span>
     </span>
    </li>
   </ol>
  </div>
 </div>
 <!-- 
NewPP limit report
Parsed by mw‐api‐ext.eqiad.main‐5b47d7b8f‐n8247
Cached time: 20240722234123
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.278 seconds
Real time usage: 0.497 seconds
Preprocessor visited node count: 829/1000000
Post‐expand include size: 32385/2097152 bytes
Template argument size: 678/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 41563/5000000 bytes
Lua time usage: 0.178/10.000 seconds
Lua memory usage: 5606648/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
 <!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  391.079      1 -total
 57.98%  226.762      1 Template:Reflist
 38.93%  152.231      2 Template:Cite_book
 32.92%  128.741      1 Template:More_citations_needed
 28.24%  110.438      1 Template:Ambox
 11.96%   46.767      7 Template:Cite_journal
  7.34%   28.688      1 Template:Citation_needed
  5.72%   22.369      1 Template:Fix
  3.54%   13.856      1 Template:Find_sources_mainspace
  2.04%    7.983      2 Template:Category_handler
-->
 <!-- Saved in parser cache with key enwiki:pcache:idhash:8953380-0!canonical and timestamp 20240722234123 and revision id 1184050325. Rendering was triggered because: unknown
 -->
</div>
